{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 32\n",
    "IMAGE_HEIGHT = 32\n",
    "COLOR_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WEIGHTS = '../cifar10vgg_numpy.npz'\n",
    "weights = np.load(WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_weights(layer_name):\n",
    "    layer_type = layer_name.split('_')[0]\n",
    "    layer_num = int(layer_name.split('_')[1])\n",
    "    W = weights[\"b'\" + str(layer_name) + \"/kernel:0'\"]\n",
    "    b = weights[\"b'\" + str(layer_name) + \"/bias:0'\"]\n",
    "    if layer_type == 'conv2d':\n",
    "        beta = weights[\"b'batch_normalization_\" + str(layer_num) + \"/beta:0'\"]\n",
    "        gamma = weights[\"b'batch_normalization_\" + str(layer_num) + \"/gamma:0'\"]\n",
    "        mov_mean = weights[\"b'batch_normalization_\" + str(layer_num) + \"/moving_mean:0'\"]\n",
    "        mov_var = weights[\"b'batch_normalization_\" + str(layer_num) + \"/moving_variance:0'\"]\n",
    "        return W, b, beta, gamma, mov_mean, mov_var\n",
    "    elif layer_type == 'dense':\n",
    "        if layer_num == 1:\n",
    "            beta = weights[\"b'batch_normalization_14/beta:0'\"]\n",
    "            gamma = weights[\"b'batch_normalization_14/gamma:0'\"]\n",
    "            mov_mean = weights[\"b'batch_normalization_14/moving_mean:0'\"]\n",
    "            mov_var = weights[\"b'batch_normalization_14/moving_variance:0'\"]\n",
    "            return W, b, beta, gamma, mov_mean, mov_var\n",
    "        else:\n",
    "            return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(inputs, n_filters, name):\n",
    "    W, b, beta, gamma, mov_mean, mov_var = load_weights(name)\n",
    "    activations = tf.layers.conv2d(inputs, n_filters, [3,3], \n",
    "                                   padding='SAME',\n",
    "                                   activation=tf.nn.relu,\n",
    "                                   kernel_initializer=tf.constant_initializer(W),\n",
    "                                   bias_initializer=tf.constant_initializer(b),\n",
    "                                   trainable=False,\n",
    "                                   name=name)\n",
    "    normed = tf.layers.batch_normalization(activations,\n",
    "                                          beta_initializer=tf.constant_initializer(beta),\n",
    "                                          gamma_initializer=tf.constant_initializer(gamma),\n",
    "                                          moving_mean_initializer=tf.constant_initializer(mov_mean),\n",
    "                                          moving_variance_initializer=tf.constant_initializer(mov_var),\n",
    "                                          trainable=False,\n",
    "                                          name=name)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pool(inputs, name):\n",
    "    return tf.layers.max_pooling2d(inputs, [2,2], [2,2], padding='SAME', name='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc(inputs, name):\n",
    "    W, b, beta, gamma, mov_mean, mov_var = load_weights(name)\n",
    "    W = tf.constant(W)\n",
    "    b = tf.constant(np.reshape(b, (b.size)))\n",
    "    activations = tf.nn.relu(tf.matmul(inputs, W) + b)\n",
    "    normed = tf.layers.batch_normalization(activations,\n",
    "                                          beta_initializer=tf.constant_initializer(beta),\n",
    "                                          gamma_initializer=tf.constant_initializer(gamma),\n",
    "                                          moving_mean_initializer=tf.constant_initializer(mov_mean),\n",
    "                                          moving_variance_initializer=tf.constant_initializer(mov_var),\n",
    "                                          trainable=False,\n",
    "                                          name=name)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(inputs, name):\n",
    "    W, b = load_weights(name)\n",
    "    W = tf.constant(W)\n",
    "    b = tf.constant(np.reshape(b, (b.size)))\n",
    "    return tf.nn.softmax(tf.matmul(inputs, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 1\n",
    "img = tf.get_variable('img', initializer=np.zeros([n_images, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS], \n",
    "                                                  dtype=np.float32))\n",
    "\n",
    "conv1_1 = conv(img, 64, 'conv2d_1')\n",
    "conv1_2 = conv(conv1_1, 64, 'conv2d_2')\n",
    "pool1 = pool(conv1_2, 'pool1')\n",
    "\n",
    "conv2_1 = conv(pool1, 128, 'conv2d_3')\n",
    "conv2_2 = conv(conv2_1, 128, 'conv2d_4')\n",
    "pool2 = pool(conv2_2, 'pool2')\n",
    "\n",
    "conv3_1 = conv(pool2, 256, 'conv2d_5')\n",
    "conv3_2 = conv(conv3_1, 256, 'conv2d_6')\n",
    "conv3_3 = conv(conv3_2, 256, 'conv2d_7')\n",
    "pool3 = pool(conv3_3, 'pool3')\n",
    "\n",
    "conv4_1 = conv(pool3, 512, 'conv2d_8')\n",
    "conv4_2 = conv(conv4_1, 512, 'conv2d_9')\n",
    "conv4_3 = conv(conv4_2, 512, 'conv2d_10')\n",
    "pool4 = pool(conv4_3, 'pool4')\n",
    "\n",
    "conv5_1 = conv(pool4, 512, 'conv2d_11')\n",
    "conv5_2 = conv(conv5_1, 512, 'conv2d_12')\n",
    "conv5_3 = conv(conv5_2, 512, 'conv2d_13')\n",
    "pool5 = pool(conv5_3, 'pool5')\n",
    "\n",
    "flattened = tf.reshape(pool5, [-1, 512])\n",
    "fc6 = fc(flattened, 'dense_1')\n",
    "pred = softmax(fc6, 'dense_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        if sys.version[0] == '3':\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        elif sys.version[0] == '2':\n",
    "            dict = pickle.load(fo)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MEAN = 120.707\n",
    "STD = 64.15\n",
    "\n",
    "def normalize(X_test):\n",
    "    return (X_test - MEAN)/(STD + 1e-7)\n",
    "\n",
    "def denormalize(X_norm):\n",
    "    return (X_norm)*(STD + 1e-7) + MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_noise_image():\n",
    "    return np.random.uniform(-20, 20, (1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTENT_IMAGE = 'images/cornell-campus-small.jpg'\n",
    "OUTPUT_DIR = 'reconstructions/'\n",
    "CONTENT_LAYER = conv4_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    image = scipy.misc.imread(path)\n",
    "    image = np.reshape(image, ((1,) + image.shape)) \n",
    "    image = normalize(image)                     \n",
    "    return image\n",
    "\n",
    "def save_image(path, image):\n",
    "    image = denormalize(image)                   \n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_image = load_image(CONTENT_IMAGE)\n",
    "input_image = generate_noise_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'img:0' shape=(1, 32, 32, 3) dtype=float32_ref>\"] and loss Tensor(\"L2Loss:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-423ea21f1ab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/yuji/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    320\u001b[0m           \u001b[0;34m\"No gradients provided for any variable, check your graph for ops\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m           \u001b[0;34m\" that do not support gradients, between variables %s and loss %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'img:0' shape=(1, 32, 32, 3) dtype=float32_ref>\"] and loss Tensor(\"L2Loss:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "sess.run(img.assign(content_image))\n",
    "embedding = sess.run(CONTENT_LAYER)\n",
    "\n",
    "sess.run(img.assign(input_image))\n",
    "content_loss = tf.nn.l2_loss(sess.run(CONTENT_LAYER) - tf.constant(embedding))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "train_step = optimizer.minimize(content_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(ITERATIONS):\n",
    "    sess.run(train_step)\n",
    "    if it%100 == 0:\n",
    "        reconstruction = sess.run(img)\n",
    "        print('Iteration %d' % (it))\n",
    "        print('loss: ', sess.run(content_loss))\n",
    "\n",
    "        if not os.path.exists(OUTPUT_DIR):\n",
    "            os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "        filename = 'output/%d.png' % (it)\n",
    "        save_image(filename, reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = unpickle('cifar-10-data')\n",
    "permutation = np.random.permutation(10000)\n",
    "data = np.array(cifar10[b'data'])[permutation]\n",
    "labels = np.array(cifar10[b'labels'])[permutation]\n",
    "x_test = normalize(data.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\"))[:n_images]\n",
    "y_test = labels[:n_images]\n",
    "\n",
    "sess.close()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(img.assign(x_test))\n",
    "\n",
    "y = tf.placeholder(tf.int64, [None,], name='y')\n",
    "correct = tf.equal(tf.argmax(pred, axis=1), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "print(sess.run([accuracy], feed_dict={y:y_test}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
