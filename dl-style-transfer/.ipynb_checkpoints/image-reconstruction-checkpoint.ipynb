{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The dimensions of images in the Cifar 10 dataset\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_HEIGHT = 32\n",
    "COLOR_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pretrained weights for VGG\n",
    "# Procured from: https://github.com/geifmany/cifar-vgg\n",
    "# Converted to numpy using the h5py script included in this directory\n",
    "\n",
    "WEIGHTS = '../cifar10vgg_numpy.npz'\n",
    "weights = np.load(WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return the appropriate pretrained weights for a particular layer/layertype\n",
    "def load_weights(layer_name):\n",
    "    layer_type = layer_name.split('_')[0]\n",
    "    layer_num = int(layer_name.split('_')[1])\n",
    "    W = weights[\"b'\" + str(layer_name) + \"/kernel:0'\"]\n",
    "    b = weights[\"b'\" + str(layer_name) + \"/bias:0'\"]\n",
    "    if layer_type == 'conv2d':\n",
    "        beta = weights[\"b'batch_normalization_\" + str(layer_num) + \"/beta:0'\"]\n",
    "        gamma = weights[\"b'batch_normalization_\" + str(layer_num) + \"/gamma:0'\"]\n",
    "        mov_mean = weights[\"b'batch_normalization_\" + str(layer_num) + \"/moving_mean:0'\"]\n",
    "        mov_var = weights[\"b'batch_normalization_\" + str(layer_num) + \"/moving_variance:0'\"]\n",
    "        return W, b, beta, gamma, mov_mean, mov_var\n",
    "    elif layer_type == 'dense':\n",
    "        if layer_num == 1:\n",
    "            beta = weights[\"b'batch_normalization_14/beta:0'\"]\n",
    "            gamma = weights[\"b'batch_normalization_14/gamma:0'\"]\n",
    "            mov_mean = weights[\"b'batch_normalization_14/moving_mean:0'\"]\n",
    "            mov_var = weights[\"b'batch_normalization_14/moving_variance:0'\"]\n",
    "            return W, b, beta, gamma, mov_mean, mov_var\n",
    "        else:\n",
    "            return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a convolutional layer with specified number of filters, name and inputs\n",
    "def conv(inputs, n_filters, name):\n",
    "    W, b, beta, gamma, mov_mean, mov_var = load_weights(name)\n",
    "    activations = tf.layers.conv2d(inputs, n_filters, [3,3], \n",
    "                                   padding='SAME',\n",
    "                                   activation=tf.nn.relu,\n",
    "                                   kernel_initializer=tf.constant_initializer(W),\n",
    "                                   bias_initializer=tf.constant_initializer(b),\n",
    "                                   trainable=False,\n",
    "                                   name=name)\n",
    "    \"\"\"normed = tf.layers.batch_normalization(activations,\n",
    "                                          beta_initializer=tf.constant_initializer(beta),\n",
    "                                          gamma_initializer=tf.constant_initializer(gamma),\n",
    "                                          moving_mean_initializer=tf.constant_initializer(mov_mean),\n",
    "                                          moving_variance_initializer=tf.constant_initializer(mov_var),\n",
    "                                          trainable=False,\n",
    "                                          name=name)\"\"\"\n",
    "    normed = bn(activations, beta, gamma, mov_mean, mov_var, scope=name)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a max-pooling layer\n",
    "def pool(inputs, name):\n",
    "    return tf.layers.average_pooling2d(inputs, [2,2], [2,2], padding='SAME', name='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a batch norm tensor\n",
    "def bn(inputs, beta, gamma, avg_mean, avg_var, scope='BN'):\n",
    "    with tf.variable_scope(scope):\n",
    "        return tf.nn.batch_normalization(inputs, avg_mean, avg_var, beta, gamma, 1e-7, name='Normalized')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a specified fully connected layer\n",
    "def fc(inputs, name):\n",
    "    W, b, beta, gamma, mov_mean, mov_var = load_weights(name)\n",
    "    W = tf.constant(W)\n",
    "    b = tf.constant(np.reshape(b, (b.size)))\n",
    "    activations = tf.nn.relu(tf.matmul(inputs, W) + b)\n",
    "    \"\"\"normed = tf.layers.batch_normalization(activations,\n",
    "                                          beta_initializer=tf.constant_initializer(beta),\n",
    "                                          gamma_initializer=tf.constant_initializer(gamma),\n",
    "                                          moving_mean_initializer=tf.constant_initializer(mov_mean),\n",
    "                                          moving_variance_initializer=tf.constant_initializer(mov_var),\n",
    "                                          trainable=False,\n",
    "                                          name=name)\"\"\"\n",
    "    normed = bn(activations, beta, gamma, mov_mean, mov_var, scope=name)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a softmax tensor to add to the end of the graph\n",
    "def softmax(inputs, name):\n",
    "    W, b = load_weights(name)\n",
    "    W = tf.constant(W)\n",
    "    b = tf.constant(np.reshape(b, (b.size)))\n",
    "    return tf.nn.softmax(tf.matmul(inputs, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_images = 1\n",
    "# Create the image which will be the basis for the reconstruction\n",
    "img = tf.get_variable('img', initializer=np.zeros([n_images, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS], \n",
    "                                                  dtype=np.float32))\n",
    "\n",
    "# Create the appropriate layers for VGG 16\n",
    "\n",
    "conv1_1 = conv(img, 64, 'conv2d_1')\n",
    "conv1_2 = conv(conv1_1, 64, 'conv2d_2')\n",
    "pool1 = pool(conv1_2, 'pool1')\n",
    "\n",
    "conv2_1 = conv(pool1, 128, 'conv2d_3')\n",
    "conv2_2 = conv(conv2_1, 128, 'conv2d_4')\n",
    "pool2 = pool(conv2_2, 'pool2')\n",
    "\n",
    "conv3_1 = conv(pool2, 256, 'conv2d_5')\n",
    "conv3_2 = conv(conv3_1, 256, 'conv2d_6')\n",
    "conv3_3 = conv(conv3_2, 256, 'conv2d_7')\n",
    "pool3 = pool(conv3_3, 'pool3')\n",
    "\n",
    "conv4_1 = conv(pool3, 512, 'conv2d_8')\n",
    "conv4_2 = conv(conv4_1, 512, 'conv2d_9')\n",
    "conv4_3 = conv(conv4_2, 512, 'conv2d_10')\n",
    "pool4 = pool(conv4_3, 'pool4')\n",
    "\n",
    "conv5_1 = conv(pool4, 512, 'conv2d_11')\n",
    "conv5_2 = conv(conv5_1, 512, 'conv2d_12')\n",
    "conv5_3 = conv(conv5_2, 512, 'conv2d_13')\n",
    "pool5 = pool(conv5_3, 'pool5')\n",
    "\n",
    "flattened = tf.reshape(pool5, [-1, 512])\n",
    "fc6 = fc(flattened, 'dense_1')\n",
    "pred = softmax(fc6, 'dense_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method to extract data from cifar 10\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        if sys.version[0] == '3':\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        elif sys.version[0] == '2':\n",
    "            dict = pickle.load(fo)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MEAN = 120.707\n",
    "STD = 64.15\n",
    "\n",
    "def normalize(X_test):\n",
    "    return (X_test - MEAN)/(STD + 1e-7)\n",
    "\n",
    "def denormalize(X_norm):\n",
    "    return (X_norm)*(STD + 1e-7) + MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a random noise image to use as reconstruction\n",
    "def generate_noise_image():\n",
    "    return np.random.uniform(-20, 20, (1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTENT_IMAGE = 'images/cornell-campus-small.jpg'\n",
    "OUTPUT_DIR = 'reconstructions/'\n",
    "CONTENT_LAYER = conv2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and save images\n",
    "\n",
    "def load_image(path):\n",
    "    image = scipy.misc.imread(path)\n",
    "    image = np.reshape(image, ((1,) + image.shape)) \n",
    "    image = normalize(image)                     \n",
    "    return image\n",
    "\n",
    "def save_image(path, image):\n",
    "    image = image[0]\n",
    "    image = denormalize(image)                   \n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_image = load_image(CONTENT_IMAGE)\n",
    "input_image = generate_noise_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a tensorflow session, replace the placeholder zeros image with\n",
    "# the random noise image. Get the content information from the content image\n",
    "# Alter the input image using AdamOptimizer\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "sess.run(img.assign(content_image))\n",
    "embedding = sess.run(CONTENT_LAYER)\n",
    "\n",
    "sess.run(img.assign(input_image))\n",
    "content_loss = tf.nn.l2_loss(CONTENT_LAYER - tf.constant(embedding))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.1)\n",
    "train_step = optimizer.minimize(content_loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "loss:  19036.3\n",
      "Iteration 100\n",
      "loss:  344.249\n",
      "Iteration 200\n",
      "loss:  92.3894\n",
      "Iteration 300\n",
      "loss:  49.6849\n",
      "Iteration 400\n",
      "loss:  40.7816\n",
      "Iteration 500\n",
      "loss:  32.3433\n",
      "Iteration 600\n",
      "loss:  34.7913\n",
      "Iteration 700\n",
      "loss:  35.5221\n",
      "Iteration 800\n",
      "loss:  29.9725\n",
      "Iteration 900\n",
      "loss:  29.9884\n",
      "Iteration 1000\n",
      "loss:  28.1759\n",
      "Iteration 1100\n",
      "loss:  31.7965\n",
      "Iteration 1200\n",
      "loss:  27.771\n",
      "Iteration 1300\n",
      "loss:  26.3689\n",
      "Iteration 1400\n",
      "loss:  28.8821\n",
      "Iteration 1500\n",
      "loss:  24.3352\n",
      "Iteration 1600\n",
      "loss:  26.4387\n",
      "Iteration 1700\n",
      "loss:  29.4773\n",
      "Iteration 1800\n",
      "loss:  32.5653\n",
      "Iteration 1900\n",
      "loss:  28.9331\n",
      "Iteration 2000\n",
      "loss:  38.3607\n",
      "Iteration 2100\n",
      "loss:  26.7224\n",
      "Iteration 2200\n",
      "loss:  39.1294\n",
      "Iteration 2300\n",
      "loss:  25.6126\n",
      "Iteration 2400\n",
      "loss:  26.1927\n",
      "Iteration 2500\n",
      "loss:  25.7064\n",
      "Iteration 2600\n",
      "loss:  26.7886\n",
      "Iteration 2700\n",
      "loss:  29.5517\n",
      "Iteration 2800\n",
      "loss:  26.3325\n",
      "Iteration 2900\n",
      "loss:  23.7897\n",
      "Iteration 3000\n",
      "loss:  25.5593\n",
      "Iteration 3100\n",
      "loss:  23.9973\n",
      "Iteration 3200\n",
      "loss:  24.9602\n",
      "Iteration 3300\n",
      "loss:  31.7\n",
      "Iteration 3400\n",
      "loss:  22.5275\n",
      "Iteration 3500\n",
      "loss:  25.239\n",
      "Iteration 3600\n",
      "loss:  82.9802\n",
      "Iteration 3700\n",
      "loss:  21.426\n",
      "Iteration 3800\n",
      "loss:  37.2004\n",
      "Iteration 3900\n",
      "loss:  23.0457\n",
      "Iteration 4000\n",
      "loss:  36.3494\n",
      "Iteration 4100\n",
      "loss:  23.8037\n",
      "Iteration 4200\n",
      "loss:  24.3681\n",
      "Iteration 4300\n",
      "loss:  22.5273\n",
      "Iteration 4400\n",
      "loss:  29.3655\n",
      "Iteration 4500\n",
      "loss:  27.495\n",
      "Iteration 4600\n",
      "loss:  22.0267\n",
      "Iteration 4700\n",
      "loss:  23.6336\n",
      "Iteration 4800\n",
      "loss:  21.8234\n",
      "Iteration 4900\n",
      "loss:  34.7894\n",
      "Iteration 5000\n",
      "loss:  21.6464\n",
      "Iteration 5100\n",
      "loss:  23.2867\n",
      "Iteration 5200\n",
      "loss:  21.4501\n",
      "Iteration 5300\n",
      "loss:  21.9474\n",
      "Iteration 5400\n",
      "loss:  26.8955\n",
      "Iteration 5500\n",
      "loss:  25.6179\n",
      "Iteration 5600\n",
      "loss:  22.3583\n",
      "Iteration 5700\n",
      "loss:  23.9118\n",
      "Iteration 5800\n",
      "loss:  20.6281\n",
      "Iteration 5900\n",
      "loss:  22.5362\n",
      "Iteration 6000\n",
      "loss:  21.2549\n",
      "Iteration 6100\n",
      "loss:  22.8378\n",
      "Iteration 6200\n",
      "loss:  26.6098\n",
      "Iteration 6300\n",
      "loss:  18.4665\n",
      "Iteration 6400\n",
      "loss:  23.6842\n",
      "Iteration 6500\n",
      "loss:  28.05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-84ad9f945b3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mreconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuji/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuji/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuji/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuji/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuji/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Perform 100000 iterative changes on the noise image\n",
    "for it in range(ITERATIONS):\n",
    "    sess.run(train_step)\n",
    "    if it%100 == 0:\n",
    "        reconstruction = sess.run(img)\n",
    "        print('Iteration %d' % (it))\n",
    "        print('loss: ', sess.run(content_loss))\n",
    "\n",
    "        if not os.path.exists(OUTPUT_DIR):\n",
    "            os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "        filename = 'reconstructions/%d.png' % (it)\n",
    "        save_image(filename, reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar10 = unpickle('cifar-10-data')\n",
    "permutation = np.random.permutation(10000)\n",
    "data = np.array(cifar10[b'data'])[permutation]\n",
    "labels = np.array(cifar10[b'labels'])[permutation]\n",
    "x_test = normalize(data.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\"))[:n_images]\n",
    "y_test = labels[:n_images]\n",
    "\n",
    "sess.close()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(img.assign(x_test))\n",
    "\n",
    "y = tf.placeholder(tf.int64, [None,], name='y')\n",
    "correct = tf.equal(tf.argmax(pred, axis=1), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "print(sess.run([accuracy], feed_dict={y:y_test}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
