{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuji/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 32\n",
    "IMAGE_HEIGHT = 32\n",
    "COLOR_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WEIGHTS = 'cifar10vgg_numpy.npz'\n",
    "weights = np.load(WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(layer_name):\n",
    "    layer_type = layer_name.split('_')[0]\n",
    "    layer_num = int(layer_name.split('_')[1])\n",
    "    W = weights[\"b'\" + str(layer_name) + \"/kernel:0'\"]\n",
    "    b = weights[\"b'\" + str(layer_name) + \"/bias:0'\"]\n",
    "    if layer_type == 'conv2d':\n",
    "        beta = weights[\"b'batch_normalization_\" + str(layer_num) + \"/beta:0'\"]\n",
    "        gamma = weights[\"b'batch_normalization_\" + str(layer_num) + \"/gamma:0'\"]\n",
    "        mov_mean = weights[\"b'batch_normalization_\" + str(layer_num) + \"/moving_mean:0'\"]\n",
    "        mov_var = weights[\"b'batch_normalization_\" + str(layer_num) + \"/moving_variance:0'\"]\n",
    "        return W, b, beta, gamma, mov_mean, mov_var\n",
    "    elif layer_type == 'dense':\n",
    "        if layer_num == 1:\n",
    "            beta = weights[\"b'batch_normalization_14/beta:0'\"]\n",
    "            gamma = weights[\"b'batch_normalization_14/gamma:0'\"]\n",
    "            mov_mean = weights[\"b'batch_normalization_14/moving_mean:0'\"]\n",
    "            mov_var = weights[\"b'batch_normalization_14/moving_variance:0'\"]\n",
    "            return W, b, beta, gamma, mov_mean, mov_var\n",
    "        else:\n",
    "            return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(inputs, n_filters, name):\n",
    "    W, b, beta, gamma, mov_mean, mov_var = load_weights(name)\n",
    "    activations = tf.layers.conv2d(inputs, n_filters, [3,3], \n",
    "                                   padding='SAME',\n",
    "                                   activation=tf.nn.relu,\n",
    "                                   kernel_initializer=tf.constant_initializer(W),\n",
    "                                   bias_initializer=tf.constant_initializer(b),\n",
    "                                   trainable=False,\n",
    "                                   name=name)\n",
    "    \"\"\"normed = tf.layers.batch_normalization(activations,\n",
    "                                          beta_initializer=tf.constant_initializer(beta),\n",
    "                                          gamma_initializer=tf.constant_initializer(gamma),\n",
    "                                          moving_mean_initializer=tf.constant_initializer(mov_mean),\n",
    "                                          moving_variance_initializer=tf.constant_initializer(mov_var),\n",
    "                                          trainable=False,\n",
    "                                          name=name)\"\"\"\n",
    "    normed = bn(activations, beta, gamma, mov_mean, mov_var, scope=name)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pool(inputs, name):\n",
    "    return tf.layers.average_pooling2d(inputs, [2,2], [2,2], padding='SAME', name='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bn(inputs, beta, gamma, avg_mean, avg_var, scope='BN'):\n",
    "    with tf.variable_scope(scope):\n",
    "        return tf.nn.batch_normalization(inputs, avg_mean, avg_var, beta, gamma, 1e-7, name='Normalized')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(inputs, name):\n",
    "    W, b, beta, gamma, mov_mean, mov_var = load_weights(name)\n",
    "    W = tf.constant(W)\n",
    "    b = tf.constant(np.reshape(b, (b.size)))\n",
    "    activations = tf.nn.relu(tf.matmul(inputs, W) + b)\n",
    "    \"\"\"normed = tf.layers.batch_normalization(activations,\n",
    "                                          beta_initializer=tf.constant_initializer(beta),\n",
    "                                          gamma_initializer=tf.constant_initializer(gamma),\n",
    "                                          moving_mean_initializer=tf.constant_initializer(mov_mean),\n",
    "                                          moving_variance_initializer=tf.constant_initializer(mov_var),\n",
    "                                          trainable=False,\n",
    "                                          name=name)\"\"\"\n",
    "    normed = bn(activations, beta, gamma, mov_mean, mov_var, scope=name)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(inputs, name):\n",
    "    W, b = load_weights(name)\n",
    "    W = tf.constant(W)\n",
    "    b = tf.constant(np.reshape(b, (b.size)))\n",
    "    return tf.nn.softmax(tf.matmul(inputs, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_images = 1\n",
    "img = tf.get_variable('img', initializer=np.zeros([n_images, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS], \n",
    "                                                  dtype=np.float32))\n",
    "\n",
    "conv1_1 = conv(img, 64, 'conv2d_1')\n",
    "conv1_2 = conv(conv1_1, 64, 'conv2d_2')\n",
    "pool1 = pool(conv1_2, 'pool1')\n",
    "\n",
    "conv2_1 = conv(pool1, 128, 'conv2d_3')\n",
    "conv2_2 = conv(conv2_1, 128, 'conv2d_4')\n",
    "pool2 = pool(conv2_2, 'pool2')\n",
    "\n",
    "conv3_1 = conv(pool2, 256, 'conv2d_5')\n",
    "conv3_2 = conv(conv3_1, 256, 'conv2d_6')\n",
    "conv3_3 = conv(conv3_2, 256, 'conv2d_7')\n",
    "pool3 = pool(conv3_3, 'pool3')\n",
    "\n",
    "conv4_1 = conv(pool3, 512, 'conv2d_8')\n",
    "conv4_2 = conv(conv4_1, 512, 'conv2d_9')\n",
    "conv4_3 = conv(conv4_2, 512, 'conv2d_10')\n",
    "pool4 = pool(conv4_3, 'pool4')\n",
    "\n",
    "conv5_1 = conv(pool4, 512, 'conv2d_11')\n",
    "conv5_2 = conv(conv5_1, 512, 'conv2d_12')\n",
    "conv5_3 = conv(conv5_2, 512, 'conv2d_13')\n",
    "pool5 = pool(conv5_3, 'pool5')\n",
    "\n",
    "flattened = tf.reshape(pool5, [-1, 512])\n",
    "fc6 = fc(flattened, 'dense_1')\n",
    "pred = softmax(fc6, 'dense_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        if sys.version[0] == '3':\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        elif sys.version[0] == '2':\n",
    "            dict = pickle.load(fo)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = 120.707\n",
    "STD = 64.15\n",
    "\n",
    "def normalize(X_test):\n",
    "    return (X_test - MEAN)/(STD + 1e-7)\n",
    "\n",
    "def denormalize(X_norm):\n",
    "    return (X_norm)*(STD + 1e-7) + MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_noise_image():\n",
    "    return np.random.uniform(-20, 20, (1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTENT_IMAGE = 'images/boats.jpg'\n",
    "OUTPUT_DIR = 'reconstructions/'\n",
    "CONTENT_LAYER = conv2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    image = scipy.misc.imread(path)\n",
    "    image = np.reshape(image, ((1,) + image.shape)) \n",
    "    image = normalize(image)                     \n",
    "    return image\n",
    "\n",
    "def save_image(path, image):\n",
    "    image = image[0]\n",
    "    image = denormalize(image)                   \n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuji/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "content_image = load_image(CONTENT_IMAGE)\n",
    "input_image = generate_noise_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "sess.run(img.assign(content_image))\n",
    "embedding = sess.run(CONTENT_LAYER)\n",
    "\n",
    "sess.run(img.assign(input_image))\n",
    "content_loss = tf.nn.l2_loss(CONTENT_LAYER - tf.constant(embedding))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.1)\n",
    "train_step = optimizer.minimize(content_loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "loss:  8677.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuji/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100\n",
      "loss:  429.465\n",
      "Iteration 200\n",
      "loss:  114.324\n",
      "Iteration 300\n",
      "loss:  13.3809\n",
      "Iteration 400\n",
      "loss:  6.18643\n",
      "Iteration 500\n",
      "loss:  8.92616\n",
      "Iteration 600\n",
      "loss:  7.39892\n",
      "Iteration 700\n",
      "loss:  4.29199\n",
      "Iteration 800\n",
      "loss:  4.03492\n",
      "Iteration 900\n",
      "loss:  2.22095\n",
      "Iteration 1000\n",
      "loss:  2.48705\n",
      "Iteration 1100\n",
      "loss:  19.6076\n",
      "Iteration 1200\n",
      "loss:  2.33727\n",
      "Iteration 1300\n",
      "loss:  6.25423\n",
      "Iteration 1400\n",
      "loss:  2.38384\n",
      "Iteration 1500\n",
      "loss:  4.98166\n",
      "Iteration 1600\n",
      "loss:  2.60182\n",
      "Iteration 1700\n",
      "loss:  4.29001\n",
      "Iteration 1800\n",
      "loss:  8.70064\n",
      "Iteration 1900\n",
      "loss:  3.2382\n",
      "Iteration 2000\n",
      "loss:  6.37675\n",
      "Iteration 2100\n",
      "loss:  6.52236\n",
      "Iteration 2200\n",
      "loss:  3.44389\n",
      "Iteration 2300\n",
      "loss:  2.94793\n",
      "Iteration 2400\n",
      "loss:  2.78668\n",
      "Iteration 2500\n",
      "loss:  3.7261\n",
      "Iteration 2600\n",
      "loss:  7.26078\n",
      "Iteration 2700\n",
      "loss:  3.01517\n",
      "Iteration 2800\n",
      "loss:  5.90278\n",
      "Iteration 2900\n",
      "loss:  53.0226\n",
      "Iteration 3000\n",
      "loss:  3.72896\n",
      "Iteration 3100\n",
      "loss:  7.26747\n",
      "Iteration 3200\n",
      "loss:  3.94283\n",
      "Iteration 3300\n",
      "loss:  6.92226\n",
      "Iteration 3400\n",
      "loss:  17.0087\n",
      "Iteration 3500\n",
      "loss:  2.37551\n",
      "Iteration 3600\n",
      "loss:  3.08688\n",
      "Iteration 3700\n",
      "loss:  3.41662\n",
      "Iteration 3800\n",
      "loss:  2.0754\n",
      "Iteration 3900\n",
      "loss:  4.79741\n",
      "Iteration 4000\n",
      "loss:  3.89737\n",
      "Iteration 4100\n",
      "loss:  13.9772\n",
      "Iteration 4200\n",
      "loss:  2.62902\n",
      "Iteration 4300\n",
      "loss:  7.71401\n",
      "Iteration 4400\n",
      "loss:  2.82127\n",
      "Iteration 4500\n",
      "loss:  6.47789\n",
      "Iteration 4600\n",
      "loss:  4.18498\n",
      "Iteration 4700\n",
      "loss:  4.5613\n",
      "Iteration 4800\n",
      "loss:  3.02154\n",
      "Iteration 4900\n",
      "loss:  288.211\n",
      "Iteration 5000\n",
      "loss:  2.72828\n",
      "Iteration 5100\n",
      "loss:  3.65295\n",
      "Iteration 5200\n",
      "loss:  4.53351\n",
      "Iteration 5300\n",
      "loss:  2.09269\n",
      "Iteration 5400\n",
      "loss:  4.4651\n",
      "Iteration 5500\n",
      "loss:  2.81714\n",
      "Iteration 5600\n",
      "loss:  3.51437\n",
      "Iteration 5700\n",
      "loss:  6.83904\n",
      "Iteration 5800\n",
      "loss:  3.53211\n",
      "Iteration 5900\n",
      "loss:  3.05128\n",
      "Iteration 6000\n",
      "loss:  5.7622\n",
      "Iteration 6100\n",
      "loss:  3.32672\n",
      "Iteration 6200\n",
      "loss:  17.6944\n",
      "Iteration 6300\n",
      "loss:  3.49344\n",
      "Iteration 6400\n",
      "loss:  1.94798\n",
      "Iteration 6500\n",
      "loss:  1.26616\n",
      "Iteration 6600\n",
      "loss:  3.07024\n",
      "Iteration 6700\n",
      "loss:  4.69245\n",
      "Iteration 6800\n",
      "loss:  9.13287\n",
      "Iteration 6900\n",
      "loss:  2.86126\n",
      "Iteration 7000\n",
      "loss:  4.24639\n",
      "Iteration 7100\n",
      "loss:  6.56343\n",
      "Iteration 7200\n",
      "loss:  5.68247\n",
      "Iteration 7300\n",
      "loss:  1.52671\n",
      "Iteration 7400\n",
      "loss:  2.27759\n",
      "Iteration 7500\n",
      "loss:  5.36469\n",
      "Iteration 7600\n",
      "loss:  1.2724\n",
      "Iteration 7700\n",
      "loss:  1.84945\n",
      "Iteration 7800\n",
      "loss:  2.05015\n",
      "Iteration 7900\n",
      "loss:  2.52318\n",
      "Iteration 8000\n",
      "loss:  106.244\n",
      "Iteration 8100\n",
      "loss:  3.01998\n",
      "Iteration 8200\n",
      "loss:  2.91405\n",
      "Iteration 8300\n",
      "loss:  4.44953\n",
      "Iteration 8400\n",
      "loss:  2.27892\n",
      "Iteration 8500\n",
      "loss:  2.08438\n",
      "Iteration 8600\n",
      "loss:  2.2686\n",
      "Iteration 8700\n",
      "loss:  2.901\n",
      "Iteration 8800\n",
      "loss:  1.92015\n",
      "Iteration 8900\n",
      "loss:  3.30087\n",
      "Iteration 9000\n",
      "loss:  3.23426\n",
      "Iteration 9100\n",
      "loss:  30.9908\n",
      "Iteration 9200\n",
      "loss:  9.04157\n",
      "Iteration 9300\n",
      "loss:  2.91362\n",
      "Iteration 9400\n",
      "loss:  2.60754\n",
      "Iteration 9500\n",
      "loss:  2.17495\n",
      "Iteration 9600\n",
      "loss:  1.87065\n",
      "Iteration 9700\n",
      "loss:  4.01857\n",
      "Iteration 9800\n",
      "loss:  6.08937\n",
      "Iteration 9900\n",
      "loss:  3.77673\n"
     ]
    }
   ],
   "source": [
    "for it in range(ITERATIONS):\n",
    "    sess.run(train_step)\n",
    "    if it%100 == 0:\n",
    "        reconstruction = sess.run(img)\n",
    "        print('Iteration %d' % (it))\n",
    "        print('loss: ', sess.run(content_loss))\n",
    "\n",
    "        if not os.path.exists(OUTPUT_DIR):\n",
    "            os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "        filename = 'reconstructions/boats%d.png' % (it)\n",
    "        save_image(filename, reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n"
     ]
    }
   ],
   "source": [
    "cifar10 = unpickle('cifar-10-data')\n",
    "permutation = np.random.permutation(10000)\n",
    "data = np.array(cifar10[b'data'])[permutation]\n",
    "labels = np.array(cifar10[b'labels'])[permutation]\n",
    "x_test = normalize(data.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\"))[:n_images]\n",
    "y_test = labels[:n_images]\n",
    "\n",
    "sess.close()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(img.assign(x_test))\n",
    "\n",
    "y = tf.placeholder(tf.int64, [None,], name='y')\n",
    "correct = tf.equal(tf.argmax(pred, axis=1), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "print(sess.run([accuracy], feed_dict={y:y_test}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
