{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuji/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 32\n",
    "IMAGE_HEIGHT = 32\n",
    "COLOR_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WEIGHTS = 'cifar10vgg_numpy.npz'\n",
    "weights = np.load(WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(layer_name):\n",
    "    layer_type = layer_name.split('_')[0]\n",
    "    layer_num = int(layer_name.split('_')[1])\n",
    "    W = weights[\"b'\" + str(layer_name) + \"/kernel:0'\"]\n",
    "    b = weights[\"b'\" + str(layer_name) + \"/bias:0'\"]\n",
    "    if layer_type == 'conv2d':\n",
    "        beta = weights[\"b'batch_normalization_\" + str(layer_num) + \"/beta:0'\"]\n",
    "        gamma = weights[\"b'batch_normalization_\" + str(layer_num) + \"/gamma:0'\"]\n",
    "        mov_mean = weights[\"b'batch_normalization_\" + str(layer_num) + \"/moving_mean:0'\"]\n",
    "        mov_var = weights[\"b'batch_normalization_\" + str(layer_num) + \"/moving_variance:0'\"]\n",
    "        return W, b, beta, gamma, mov_mean, mov_var\n",
    "    elif layer_type == 'dense':\n",
    "        if layer_num == 1:\n",
    "            beta = weights[\"b'batch_normalization_14/beta:0'\"]\n",
    "            gamma = weights[\"b'batch_normalization_14/gamma:0'\"]\n",
    "            mov_mean = weights[\"b'batch_normalization_14/moving_mean:0'\"]\n",
    "            mov_var = weights[\"b'batch_normalization_14/moving_variance:0'\"]\n",
    "            return W, b, beta, gamma, mov_mean, mov_var\n",
    "        else:\n",
    "            return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(inputs, n_filters, name):\n",
    "    W, b, beta, gamma, mov_mean, mov_var = load_weights(name)\n",
    "    activations = tf.layers.conv2d(inputs, n_filters, [3,3], \n",
    "                                   padding='SAME',\n",
    "                                   activation=tf.nn.relu,\n",
    "                                   kernel_initializer=tf.constant_initializer(W),\n",
    "                                   bias_initializer=tf.constant_initializer(b),\n",
    "                                   trainable=False,\n",
    "                                   name=name)\n",
    "    \"\"\"normed = tf.layers.batch_normalization(activations,\n",
    "                                          beta_initializer=tf.constant_initializer(beta),\n",
    "                                          gamma_initializer=tf.constant_initializer(gamma),\n",
    "                                          moving_mean_initializer=tf.constant_initializer(mov_mean),\n",
    "                                          moving_variance_initializer=tf.constant_initializer(mov_var),\n",
    "                                          trainable=False,\n",
    "                                          name=name)\"\"\"\n",
    "    normed = bn(activations, beta, gamma, mov_mean, mov_var, scope=name)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pool(inputs, name):\n",
    "    return tf.layers.average_pooling2d(inputs, [2,2], [2,2], padding='SAME', name='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bn(inputs, beta, gamma, avg_mean, avg_var, scope='BN'):\n",
    "    with tf.variable_scope(scope):\n",
    "        return tf.nn.batch_normalization(inputs, avg_mean, avg_var, beta, gamma, 1e-7, name='Normalized')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(inputs, name):\n",
    "    W, b, beta, gamma, mov_mean, mov_var = load_weights(name)\n",
    "    W = tf.constant(W)\n",
    "    b = tf.constant(np.reshape(b, (b.size)))\n",
    "    activations = tf.nn.relu(tf.matmul(inputs, W) + b)\n",
    "    \"\"\"normed = tf.layers.batch_normalization(activations,\n",
    "                                          beta_initializer=tf.constant_initializer(beta),\n",
    "                                          gamma_initializer=tf.constant_initializer(gamma),\n",
    "                                          moving_mean_initializer=tf.constant_initializer(mov_mean),\n",
    "                                          moving_variance_initializer=tf.constant_initializer(mov_var),\n",
    "                                          trainable=False,\n",
    "                                          name=name)\"\"\"\n",
    "    normed = bn(activations, beta, gamma, mov_mean, mov_var, scope=name)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(inputs, name):\n",
    "    W, b = load_weights(name)\n",
    "    W = tf.constant(W)\n",
    "    b = tf.constant(np.reshape(b, (b.size)))\n",
    "    return tf.nn.softmax(tf.matmul(inputs, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_images = 1\n",
    "img = tf.get_variable('img', initializer=np.zeros([n_images, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS], \n",
    "                                                  dtype=np.float32))\n",
    "\n",
    "conv1_1 = conv(img, 64, 'conv2d_1')\n",
    "conv1_2 = conv(conv1_1, 64, 'conv2d_2')\n",
    "pool1 = pool(conv1_2, 'pool1')\n",
    "\n",
    "conv2_1 = conv(pool1, 128, 'conv2d_3')\n",
    "conv2_2 = conv(conv2_1, 128, 'conv2d_4')\n",
    "pool2 = pool(conv2_2, 'pool2')\n",
    "\n",
    "conv3_1 = conv(pool2, 256, 'conv2d_5')\n",
    "conv3_2 = conv(conv3_1, 256, 'conv2d_6')\n",
    "conv3_3 = conv(conv3_2, 256, 'conv2d_7')\n",
    "pool3 = pool(conv3_3, 'pool3')\n",
    "\n",
    "conv4_1 = conv(pool3, 512, 'conv2d_8')\n",
    "conv4_2 = conv(conv4_1, 512, 'conv2d_9')\n",
    "conv4_3 = conv(conv4_2, 512, 'conv2d_10')\n",
    "pool4 = pool(conv4_3, 'pool4')\n",
    "\n",
    "conv5_1 = conv(pool4, 512, 'conv2d_11')\n",
    "conv5_2 = conv(conv5_1, 512, 'conv2d_12')\n",
    "conv5_3 = conv(conv5_2, 512, 'conv2d_13')\n",
    "pool5 = pool(conv5_3, 'pool5')\n",
    "\n",
    "flattened = tf.reshape(pool5, [-1, 512])\n",
    "fc6 = fc(flattened, 'dense_1')\n",
    "pred = softmax(fc6, 'dense_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        if sys.version[0] == '3':\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        elif sys.version[0] == '2':\n",
    "            dict = pickle.load(fo)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = 120.707\n",
    "STD = 64.15\n",
    "\n",
    "def normalize(X_test):\n",
    "    return (X_test - MEAN)/(STD + 1e-7)\n",
    "\n",
    "def denormalize(X_norm):\n",
    "    return (X_norm)*(STD + 1e-7) + MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_noise_image():\n",
    "    return np.random.uniform(-20, 20, (1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTENT_IMAGE = 'images/cornell-campus-small.jpg'\n",
    "OUTPUT_DIR = 'reconstructions/'\n",
    "CONTENT_LAYER = conv2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    image = scipy.misc.imread(path)\n",
    "    image = np.reshape(image, ((1,) + image.shape)) \n",
    "    image = normalize(image)                     \n",
    "    return image\n",
    "\n",
    "def save_image(path, image):\n",
    "    image = image[0]\n",
    "    image = denormalize(image)                   \n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuji/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "content_image = load_image(CONTENT_IMAGE)\n",
    "input_image = generate_noise_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "sess.run(img.assign(content_image))\n",
    "embedding = sess.run(CONTENT_LAYER)\n",
    "\n",
    "sess.run(img.assign(input_image))\n",
    "content_loss = tf.nn.l2_loss(CONTENT_LAYER - tf.constant(embedding))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.1)\n",
    "train_step = optimizer.minimize(content_loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "loss:  19036.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuji/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100\n",
      "loss:  344.249\n",
      "Iteration 200\n",
      "loss:  92.3894\n",
      "Iteration 300\n",
      "loss:  49.6849\n",
      "Iteration 400\n",
      "loss:  40.7816\n",
      "Iteration 500\n",
      "loss:  32.3433\n",
      "Iteration 600\n",
      "loss:  34.7913\n",
      "Iteration 700\n",
      "loss:  35.5221\n",
      "Iteration 800\n",
      "loss:  29.9725\n",
      "Iteration 900\n",
      "loss:  29.9884\n",
      "Iteration 1000\n",
      "loss:  28.1759\n",
      "Iteration 1100\n",
      "loss:  31.7965\n",
      "Iteration 1200\n",
      "loss:  27.771\n",
      "Iteration 1300\n",
      "loss:  26.3689\n",
      "Iteration 1400\n",
      "loss:  28.8821\n",
      "Iteration 1500\n",
      "loss:  24.3352\n",
      "Iteration 1600\n",
      "loss:  26.4387\n",
      "Iteration 1700\n",
      "loss:  29.4773\n",
      "Iteration 1800\n",
      "loss:  32.5653\n",
      "Iteration 1900\n",
      "loss:  28.9331\n",
      "Iteration 2000\n",
      "loss:  38.3607\n",
      "Iteration 2100\n",
      "loss:  26.7224\n",
      "Iteration 2200\n",
      "loss:  39.1294\n",
      "Iteration 2300\n",
      "loss:  25.6126\n",
      "Iteration 2400\n",
      "loss:  26.1927\n",
      "Iteration 2500\n",
      "loss:  25.7064\n",
      "Iteration 2600\n",
      "loss:  26.7886\n",
      "Iteration 2700\n",
      "loss:  29.5517\n",
      "Iteration 2800\n",
      "loss:  26.3325\n",
      "Iteration 2900\n",
      "loss:  23.7897\n",
      "Iteration 3000\n",
      "loss:  25.5593\n",
      "Iteration 3100\n",
      "loss:  23.9973\n",
      "Iteration 3200\n",
      "loss:  24.9602\n",
      "Iteration 3300\n",
      "loss:  31.7\n",
      "Iteration 3400\n",
      "loss:  22.5275\n",
      "Iteration 3500\n",
      "loss:  25.239\n",
      "Iteration 3600\n",
      "loss:  82.9802\n",
      "Iteration 3700\n",
      "loss:  21.426\n",
      "Iteration 3800\n",
      "loss:  37.2004\n",
      "Iteration 3900\n",
      "loss:  23.0457\n",
      "Iteration 4000\n",
      "loss:  36.3494\n",
      "Iteration 4100\n",
      "loss:  23.8037\n",
      "Iteration 4200\n",
      "loss:  24.3681\n",
      "Iteration 4300\n",
      "loss:  22.5273\n",
      "Iteration 4400\n",
      "loss:  29.3655\n",
      "Iteration 4500\n",
      "loss:  27.495\n",
      "Iteration 4600\n",
      "loss:  22.0267\n",
      "Iteration 4700\n",
      "loss:  23.6336\n",
      "Iteration 4800\n",
      "loss:  21.8234\n",
      "Iteration 4900\n",
      "loss:  34.7894\n",
      "Iteration 5000\n",
      "loss:  21.6464\n",
      "Iteration 5100\n",
      "loss:  23.2867\n",
      "Iteration 5200\n",
      "loss:  21.4501\n",
      "Iteration 5300\n",
      "loss:  21.9474\n",
      "Iteration 5400\n",
      "loss:  26.8955\n",
      "Iteration 5500\n",
      "loss:  25.6179\n",
      "Iteration 5600\n",
      "loss:  22.3583\n",
      "Iteration 5700\n",
      "loss:  23.9118\n",
      "Iteration 5800\n",
      "loss:  20.6281\n",
      "Iteration 5900\n",
      "loss:  22.5362\n",
      "Iteration 6000\n",
      "loss:  21.2549\n",
      "Iteration 6100\n",
      "loss:  22.8378\n",
      "Iteration 6200\n",
      "loss:  26.6098\n",
      "Iteration 6300\n",
      "loss:  18.4665\n",
      "Iteration 6400\n",
      "loss:  23.6842\n",
      "Iteration 6500\n",
      "loss:  28.05\n",
      "Iteration 6600\n",
      "loss:  19.6051\n",
      "Iteration 6700\n",
      "loss:  19.2485\n",
      "Iteration 6800\n",
      "loss:  18.875\n",
      "Iteration 6900\n",
      "loss:  21.902\n",
      "Iteration 7000\n",
      "loss:  24.2393\n",
      "Iteration 7100\n",
      "loss:  24.7857\n",
      "Iteration 7200\n",
      "loss:  20.6988\n",
      "Iteration 7300\n",
      "loss:  19.1739\n",
      "Iteration 7400\n",
      "loss:  23.2825\n",
      "Iteration 7500\n",
      "loss:  21.6738\n",
      "Iteration 7600\n",
      "loss:  21.5594\n",
      "Iteration 7700\n",
      "loss:  69.8596\n",
      "Iteration 7800\n",
      "loss:  27.1048\n",
      "Iteration 7900\n",
      "loss:  20.2068\n",
      "Iteration 8000\n",
      "loss:  31.7128\n",
      "Iteration 8100\n",
      "loss:  29.2119\n",
      "Iteration 8200\n",
      "loss:  19.1435\n",
      "Iteration 8300\n",
      "loss:  22.7385\n",
      "Iteration 8400\n",
      "loss:  20.6972\n",
      "Iteration 8500\n",
      "loss:  23.5061\n",
      "Iteration 8600\n",
      "loss:  18.2788\n",
      "Iteration 8700\n",
      "loss:  21.3511\n",
      "Iteration 8800\n",
      "loss:  23.6415\n",
      "Iteration 8900\n",
      "loss:  21.3496\n",
      "Iteration 9000\n",
      "loss:  21.1391\n",
      "Iteration 9100\n",
      "loss:  75.0339\n",
      "Iteration 9200\n",
      "loss:  18.3242\n",
      "Iteration 9300\n",
      "loss:  18.6868\n",
      "Iteration 9400\n",
      "loss:  20.2304\n",
      "Iteration 9500\n",
      "loss:  28.2637\n",
      "Iteration 9600\n",
      "loss:  30.9439\n",
      "Iteration 9700\n",
      "loss:  28.5297\n",
      "Iteration 9800\n",
      "loss:  22.8895\n",
      "Iteration 9900\n",
      "loss:  20.0035\n",
      "Iteration 10000\n",
      "loss:  23.6451\n",
      "Iteration 10100\n",
      "loss:  21.2348\n",
      "Iteration 10200\n",
      "loss:  55.9012\n",
      "Iteration 10300\n",
      "loss:  18.8063\n",
      "Iteration 10400\n",
      "loss:  21.2456\n",
      "Iteration 10500\n",
      "loss:  18.3895\n",
      "Iteration 10600\n",
      "loss:  17.5516\n",
      "Iteration 10700\n",
      "loss:  25.1853\n",
      "Iteration 10800\n",
      "loss:  19.5147\n",
      "Iteration 10900\n",
      "loss:  25.726\n",
      "Iteration 11000\n",
      "loss:  22.7844\n",
      "Iteration 11100\n",
      "loss:  24.5955\n",
      "Iteration 11200\n",
      "loss:  28.7215\n",
      "Iteration 11300\n",
      "loss:  21.9544\n",
      "Iteration 11400\n",
      "loss:  18.6303\n",
      "Iteration 11500\n",
      "loss:  27.0208\n",
      "Iteration 11600\n",
      "loss:  34.4666\n",
      "Iteration 11700\n",
      "loss:  17.315\n",
      "Iteration 11800\n",
      "loss:  26.2029\n",
      "Iteration 11900\n",
      "loss:  24.9738\n",
      "Iteration 12000\n",
      "loss:  20.168\n",
      "Iteration 12100\n",
      "loss:  26.6522\n",
      "Iteration 12200\n",
      "loss:  17.8258\n",
      "Iteration 12300\n",
      "loss:  21.8675\n",
      "Iteration 12400\n",
      "loss:  28.8161\n",
      "Iteration 12500\n",
      "loss:  19.657\n",
      "Iteration 12600\n",
      "loss:  21.8808\n",
      "Iteration 12700\n",
      "loss:  31.1478\n",
      "Iteration 12800\n",
      "loss:  18.4392\n",
      "Iteration 12900\n",
      "loss:  20.2919\n",
      "Iteration 13000\n",
      "loss:  30.518\n",
      "Iteration 13100\n",
      "loss:  99.4589\n",
      "Iteration 13200\n",
      "loss:  19.0861\n",
      "Iteration 13300\n",
      "loss:  19.9126\n",
      "Iteration 13400\n",
      "loss:  25.125\n",
      "Iteration 13500\n",
      "loss:  18.941\n",
      "Iteration 13600\n",
      "loss:  23.5715\n",
      "Iteration 13700\n",
      "loss:  26.7424\n",
      "Iteration 13800\n",
      "loss:  17.0724\n",
      "Iteration 13900\n",
      "loss:  28.1057\n",
      "Iteration 14000\n",
      "loss:  19.565\n",
      "Iteration 14100\n",
      "loss:  18.6447\n",
      "Iteration 14200\n",
      "loss:  22.2213\n",
      "Iteration 14300\n",
      "loss:  21.1462\n",
      "Iteration 14400\n",
      "loss:  18.7708\n",
      "Iteration 14500\n",
      "loss:  20.5936\n",
      "Iteration 14600\n",
      "loss:  19.4131\n",
      "Iteration 14700\n",
      "loss:  37.9371\n",
      "Iteration 14800\n",
      "loss:  17.8498\n",
      "Iteration 14900\n",
      "loss:  23.8126\n",
      "Iteration 15000\n",
      "loss:  21.509\n",
      "Iteration 15100\n",
      "loss:  23.2871\n",
      "Iteration 15200\n",
      "loss:  18.6479\n",
      "Iteration 15300\n",
      "loss:  20.0883\n",
      "Iteration 15400\n",
      "loss:  21.5274\n",
      "Iteration 15500\n",
      "loss:  34.3476\n",
      "Iteration 15600\n",
      "loss:  19.5107\n",
      "Iteration 15700\n",
      "loss:  22.5693\n",
      "Iteration 15800\n",
      "loss:  28.4968\n",
      "Iteration 15900\n",
      "loss:  18.6085\n",
      "Iteration 16000\n",
      "loss:  19.9293\n",
      "Iteration 16100\n",
      "loss:  26.413\n",
      "Iteration 16200\n",
      "loss:  32.4936\n",
      "Iteration 16300\n",
      "loss:  17.848\n",
      "Iteration 16400\n",
      "loss:  18.0693\n",
      "Iteration 16500\n",
      "loss:  22.8386\n",
      "Iteration 16600\n",
      "loss:  16.8618\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-84ad9f945b3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mreconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuji/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuji/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuji/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuji/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuji/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for it in range(ITERATIONS):\n",
    "    sess.run(train_step)\n",
    "    if it%100 == 0:\n",
    "        reconstruction = sess.run(img)\n",
    "        print('Iteration %d' % (it))\n",
    "        print('loss: ', sess.run(content_loss))\n",
    "\n",
    "        if not os.path.exists(OUTPUT_DIR):\n",
    "            os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "        filename = 'reconstructions/cornell%d.png' % (it)\n",
    "        save_image(filename, reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar10 = unpickle('cifar-10-data')\n",
    "permutation = np.random.permutation(10000)\n",
    "data = np.array(cifar10[b'data'])[permutation]\n",
    "labels = np.array(cifar10[b'labels'])[permutation]\n",
    "x_test = normalize(data.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\"))[:n_images]\n",
    "y_test = labels[:n_images]\n",
    "\n",
    "sess.close()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(img.assign(x_test))\n",
    "\n",
    "y = tf.placeholder(tf.int64, [None,], name='y')\n",
    "correct = tf.equal(tf.argmax(pred, axis=1), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "print(sess.run([accuracy], feed_dict={y:y_test}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
