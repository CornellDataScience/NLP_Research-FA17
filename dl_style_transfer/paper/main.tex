\documentclass{vldb}
\usepackage{graphicx}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage[capposition=top]{floatrow}
\usepackage{float}
\usepackage[caption = false]{subfig}
\usepackage{wrapfig}

\begin{document}

% ****************** TITLE ****************************************

\title{On the Use of K-Competitive Networks \\ for Writing Style Transfer}

% ****************** AUTHORS **************************************

\numberofauthors{3} 

\author{
\alignauthor
Luca Leeser\\
       \affaddr{Cornell University}\\
       \email{ll698@cornell.edu}
\alignauthor
Ryan Butler\\
       \affaddr{Cornell University}\\
       \email{rjb392@cornell.edu}
\and
\alignauthor 
Cameron Ibrahim\\
       \affaddr{Cornell University}\\
       \email{cai29@cornell.edu}
\alignauthor 
Yuji Akimoto\\
       \affaddr{Cornell University}\\
       \email{ya242@cornell.edu}
}

\date{1 December 2017}

\maketitle

\begin{abstract}
Writing style is a key component of the quality of any online review - a detailed and informative review is only useful insofar as it is able to retain a reader's attention. In this paper, we explore the use of $k$-competitive layers in convolutional neural networks to classify the author of a given piece of text. We then apply the techniques used in neural style transfer for images to transfer the writing style of one author onto the content written by another. Given sufficient examples of well-written reviews, our techniques can be used to globally improve the quality of reviews on Yelp.
\end{abstract}

% INTRODUCTION
\section{Introduction}
Neural style transfer \cite{GatysEB15a} has proven very successful at transferring the artistic style of an image onto the content of another. Due to the layered structure of convolutional neural networks, it was observed that later layers in the network produce feature representations of the content of an image, while the correlations between these features give a good representation of artistic style. More specifically, given a content image and style image, the algorithm treats the input to the network as a variable and simultaneously minimizes the $\ell_2$ norm between the input and content image's feature representations, and the input and style image's style representations.

\begin{figure}[h]
\subfloat{\includegraphics[width = .3\linewidth]{gates-hall.jpg}}
\hspace{0.1cm}
\subfloat{\includegraphics[width = .3\linewidth]{starry_night.jpg}}
\hspace{0.1cm}
\subfloat{\includegraphics[width = .3\linewidth]{gates-starry.png}}
\caption{\textmd{Cornell's Gates Hall stylized in the form of Vincent Van Gogh's \textit{Starry Night}.}}
\end{figure} 

Modifications that optimize computational time \cite{JohnsonAL16}, preserve the texture of the style image \cite{GatysEB15}, and preserve facial structures in the content image \cite{KaurZD17}, among others, have further advanced the art of neural style transfer for images. However, applying similar techniques to text has proven difficult for a number of reasons. Firstly, textual data lives in an extremely sparse space, and therefore it is difficult to iteratively produce better stylized text while avoiding phrases that make no sense. Secondly, style and content are much more closely linked in text than they are in images - the same writer may write two passages of text in a completely different tone, yet maintain the same underlying style in a manner that is very subtle.

In this paper, we explore the use of $k$-competitive convolutional layers, a generalization of $k$-competitive layers designed for autoencoders in \cite{KATE}, which in turn are based on $k$-sparse layers as defined in \cite{MakhzaniF13}. These layers are integrated into a word-level convolutional neural network \cite{Kim14f}, and we perform a qualitative analysis on the quality of content and style representations generated by these networks.

% RELATED WORK
\section{Related Work}

% PRELIMINARY ANALYSIS
\section{Preliminary Analysis}
The majority of implementations of style transfer for images use the VGG-19 \cite{VGG19} architecture to generate content and style representations of an image. This network was originally trained to classify between 1000 images of the ImageNet challenge dataset \cite{ILSVRC15} and therefore is able to generate informative feature representations of a very large variety of objects. Given the resources required to train a similarly robust classifier for text, we first explore the tradeoffs of using an underlying network that is trained to discriminate between a much smaller number of classes by training a VGG network with the CIFAR-10 dataset \cite{Krizhevsky09} (here, we use pre-trained weights provided by \cite{Liu15}). Although this modified network is far less generalizable in terms of classification, we found that the content representations provided by later layers of the network were still informative enough to reconstruct the original image, even for images containing objects not included in the 10 classes of CIFAR-10. 

% MODEL
\section{Model}
\subsection{Convolutional Neural Networks for Text Classification}
As the baseline for our comparisons we use a word-level convolutional neural network as designed by Yoon Kim in \cite{Kim14f}. 

\begin{figure}[h]
\includegraphics[width=\linewidth]{cnn.png}
\caption{\textmd{Structure of the baseline convolutional neural network model.}}
\end{figure}

\subsection{K-Competitive Convolutional Layers}
It has been observed that encouraging sparsity when learning representations acts as a capable reguarlizer that improves performance on classification tasks. In \cite{MakhzaniF13}, Makhzani and Frey designed the $k$-sparse autoencoder and demonstrated its effectiveness as a preprocessing step on image data. In the feedforward phase, sparsity is used as the sole non-linearity: after computing the activations $z = W^Tx + b$, only the largest $k$ entries of $z$ are kept and the rest are set to 0. 

Since textual data often has high-dimensionality, sparsity, and power-law distributions \cite{KATE}, autoencoders for text have often learned trivial features such as proper nouns specific to a certain passage. Chen and Zaki made a modification to $k$-sparse layers by introducing competition in the place of truncation: after computing the activations $z = tanh(W^Tx + b)$, only the $k$ entries with the largest absolute value are kept non-zero. These $k$ most ``competitive'' neurons are then augmented (with an amplification constant) with the \textbf{energy} of the ``losers'' that were made inactive, where the energy of a subset of neurons $H$ is defined as $\sum_{h_i \in H} |z_i|$. 

\begin{figure}[h]
\centering
\includegraphics[width=.8\linewidth]{k_complayer.png}
\caption{\textmd{A fully connected $k$-competitive layer.}}
\end{figure}

Here, we propose a generalization of $k$-competitive layers to convolutional layers.

% EXPERIMENTS
\section{Experiments}
\subsection{Datasets and Processing}
Cite NLTK

\subsection{Hyperparameters and Training}

\subsection{Comparison of Architectures}

% RESULTS
\section{Results}

% CONCLUSION
\section{Conclusion}

% FURTHER DISCUSSION
\section{Future Extensions}

% ACKNOWLEDGMENTS 
\section{Acknowledgments}
The authors would like to thank Professor Thorsten Joachims at the department of Computer Science at Cornell University for his guidance, and their fellow members of the Cornell Data Science NLP Research Team for their support.

\bibliographystyle{abbrv}
\bibliography{sources.bib}  


% APPENDIX
%pagebreak

\begin{appendix}
This is an appendix

\section{Graphs}

\end{appendix}
\end{document}