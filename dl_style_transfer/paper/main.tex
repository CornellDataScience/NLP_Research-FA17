\documentclass{vldb}
\usepackage{graphicx}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage[capposition=top]{floatrow}
\usepackage{float}
\usepackage[caption = false]{subfig}
%\usepackage{hyperref}

\begin{document}

% ****************** TITLE ****************************************

\title{On the Use of K-Competitive Networks \\ for Writing Style Transfer}

% ****************** AUTHORS **************************************

\numberofauthors{3} 

\author{
\alignauthor
Luca Leeser\\
       \affaddr{Cornell University}\\
       \email{ll698@cornell.edu}
\alignauthor
Yuji Akimoto\\
       \affaddr{Cornell University}\\
       \email{ya242@cornell.edu}
\and
\alignauthor 
Ryan Butler\\
       \affaddr{Cornell University}\\
       \email{rjb392@cornell.edu}
\alignauthor 
Cameron Ibrahim\\
       \affaddr{Cornell University}\\
       \email{cai29@cornell.edu}
}

\date{1 December 2017}

\maketitle

\begin{abstract}
Writing style is a key component of the quality of any online review - a detailed and informative review is only useful insofar as it is able to retain a reader's attention. In this paper, we explore the use of $k$-competitive layers in convolutional neural networks to classify the author of a given piece of text. We then apply the techniques used in neural style transfer for images to transfer the writing style of one author onto the content written by another. Given sufficient examples of well-written reviews, our techniques can be used to globally improve the quality of reviews on Yelp.
\end{abstract}

% INTRODUCTION
\section{Introduction}
Neural style transfer \cite{GatysEB15a} has proven very successful at transferring the artistic style of an image onto the content of another. Due to the layered structure of convolutional neural networks, it was observed that later layers in the network produce feature representations of the content of an image, while the correlations between these features give a good representation of artistic style. More specifically, given a content image and style image, the algorithm treats the input to the network as a variable and simultaneously minimizes the $\ell_2$ norm between the input and content image's feature representations, and the input and style image's style representations.

\begin{figure}[h]
\subfloat{\includegraphics[width = .3\linewidth]{gates-hall.jpg}}
\hspace{0.1cm}
\subfloat{\includegraphics[width = .3\linewidth]{starry_night.jpg}}
\hspace{0.1cm}
\subfloat{\includegraphics[width = .3\linewidth]{gates-starry.png}}
\caption{\textmd{Cornell's Gates Hall stylized in the form of Vincent Van Gogh's \textit{Starry Night}.}}
\end{figure} 

Modifications that optimize computational time \cite{JohnsonAL16}, preserve the texture of the style image \cite{GatysEB15}, and preserve facial structures in the content image \cite{KaurZD17}, among others, have further advanced the art of neural style transfer for images. However, applying similar techniques to text has proven difficult for a number of reasons. Firstly, textual data lives in an extremely sparse space, and therefore it is difficult to iteratively produce better stylized text while avoiding phrases that make no sense. Secondly, style and content are much more closely linked in text than they are in images - the same writer may write two passages of text in a completely different tone, yet maintain the same underlying style in a manner that is very subtle.

In this paper, we explore the use of $k$-competitive convolutional layers, a generalization of $k$-competitive layers designed for autoencoders in \cite{KATE}, which in turn are based on $k$-sparse layers as defined in \cite{MakhzaniF13}. These layers are integrated into a word-level convolutional neural network \cite{Kim14f}, and we perform a qualitative analysis on the quality of content and style representations generated by these networks.

% RELATED WORK
\section{Related Work}

% PRELIMINARY ANALYSIS
\section{Preliminary Analysis}
The majority of implementations of style transfer for images use the VGG-19 \cite{VGG19} architecture to generate content and style representations of an image. This network was trained to classify between 1000 images of the ImageNet challenge dataset \cite{ILSVRC15} and therefore is able to generate informative feature representations of a very large variety of objects. Given the resources required to train a similarly robust classifier for text, we first explore the tradeoffs of using an underlying network that is trained to discriminate between a much smaller number of classes by training a VGG network with the CIFAR-10 dataset \cite{Krizhevsky09} (here, we use pre-trained weights provided by \cite{Liu15}). Although this modified network is far less generalizable in terms of classification, we found that the content representations provided by later layers of the network were still informative enough to reconstruct the original image, even for images containing objects not included in the 10 classes of CIFAR-10. 

% MODEL
\section{Model}
\subsection{Convolutional Neural Networks for Text Classification}
Although recurrent neural networks have proven adept at language recognition tasks, evaluating the overall content and style of written text is a task that is less dependent on sequential information, and a hidden state is likely too small to encode enough information for our purposes. We believe that a a convolutional neural network allows us to take advantage of the success of style transfer for images, in contrast to aforementioned approaches that treat style transfer as a machine translation problem.

As the baseline for our comparisons we use a word-level convolutional neural network as designed by Yoon Kim in \cite{Kim14f}.

\begin{figure}[h]
\includegraphics[width=\linewidth]{cnn.png}
\caption{\textmd{Structure of the baseline convolutional neural network model.}}
\end{figure}

\subsection{K-Competitive Convolutional Layers}
It has been observed that encouraging sparsity when learning representations acts as a capable reguarlizer that improves performance on classification tasks. In \cite{MakhzaniF13}, Makhzani and Frey designed the $k$-sparse autoencoder and demonstrated its effectiveness as a preprocessing step on image data. In the feedforward phase, sparsity is used as the sole non-linearity: after computing the activations $z = W^Tx + b$, only the largest $k$ entries of $z$ are kept and the rest are set to 0. 

Since textual data often has high-dimensionality, sparsity, and power-law distributions \cite{KATE}, autoencoders for text have often learned trivial features such as proper nouns specific to a certain passage. Chen and Zaki made a modification to $k$-sparse layers by introducing competition in the place of truncation: after computing the activations $z = tanh(W^Tx + b)$, only the $k$ entries with the largest absolute value are kept non-zero. These $k$ most ``competitive'' neurons are then augmented (with an amplification constant) with the \textbf{energy} of the ``losers'' that were made inactive, where the energy of a subset of neurons $H$ is defined as $\sum_{h_i \in H} |z_i|$. 

\begin{figure}[h]
\centering
\includegraphics[width=.8\linewidth]{k_complayer.png}
\caption{\textmd{A fully connected $k$-competitive layer.}}
\end{figure}

Here, we propose a generalization of $k$-competitive layers to convolutional layers.

% EXPERIMENTS
\section{Experiments}
\subsection{Datasets}
We use the most prolific reviewers on Yelp\footnote{{\texttt{https://www.yelp.com/dataset/challenge}}} to generate a large amounts of text for various styles of writing. Although the reviews for a frequent user of Yelp may span a number of years, we make the assumption that a user's writing style remains constant over that period of time. This may not strictly be the case as language, particularly of the colloquial variety that is often found online, evolves over time and certain words serve as clear indicators of certain time periods. However, dealing with a time-varying vocabulary set is an extension that we have not yet considered. After identifying the most frequent reviewers, we tokenize all of their reviews using NLTK \cite{Loper02nltk:the} to generate a corpus. 

\subsection{Hyperparameters and Training}

\subsection{Comparison of Architectures}

% RESULTS
\section{Results}

% CONCLUSION
\section{Conclusion}

% FURTHER DISCUSSION
\section{Future Extensions}

% ACKNOWLEDGMENTS 
\section{Acknowledgments}
The authors would like to thank Professor Thorsten Joachims at the department of Computer Science at Cornell University for his guidance, and their fellow members of the Cornell Data Science NLP Research Team for their support.

\bibliographystyle{abbrv}
\bibliography{sources.bib}  


% APPENDIX
%pagebreak

\begin{appendix}
%\href{https://github.com/CornellDataScience/Yelp-FA17/tree/master/dl_style_transfer}{Link} to Github repository for all code associated with this paper. 

\end{appendix}
\end{document}