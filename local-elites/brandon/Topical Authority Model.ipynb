{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topical Expert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Brandon/Yelp Dataset/Yelp-FA17/local-elites/brandon\n",
      "['.DS_Store', 'business.json', 'checkin.json', 'photos.json', 'review.json', 'review5000.json', 'tip.json', 'user.json', 'user5000.json']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.listdir('/Users/Brandon/Yelp Dataset/dataset'))\n",
    "import json\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from pandas import HDFStore,DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_json_to_df(datapass):\n",
    "    '''\n",
    "    Load the json file and parse the file to pandas dataframe format\n",
    "    \n",
    "    Input:\n",
    "        datapass(str) : directory to the json file\n",
    "    Output:\n",
    "        df(dataframe) : pandas dataframe object\n",
    "    '''\n",
    "    \n",
    "    data = [] \n",
    "    with open(datapass) as data_file: \n",
    "        for f in data_file:\n",
    "            data.append(json.loads(f))\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 20.6 s, total: 1min 24s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import_file = \"/Users/Brandon/Yelp Dataset/dataset/review.json\"\n",
    "review = load_json_to_df(import_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.15 s, sys: 471 ms, total: 5.62 s\n",
      "Wall time: 6.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import_file = \"/Users/Brandon/Yelp Dataset/dataset/business.json\"\n",
    "business = load_json_to_df(import_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 26.7 s, total: 1min 26s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import_file = \"/Users/Brandon/Yelp Dataset/dataset/user.json\"\n",
    "user = load_json_to_df(import_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categoryFind(x,cat):\n",
    "    return cat in x;\n",
    "restaurantIndex = business['categories'].apply(categoryFind,cat='Restaurants')\n",
    "restaurants = business[restaurantIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.9 s, sys: 26.4 s, total: 1min 5s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "businessReviews = pd.merge(review, restaurants,on='business_id',right_index=True,sort=False)[['business_id', 'cool', 'funny', 'review_id', 'stars_x', 'text', 'useful', 'user_id', 'categories', 'review_count', 'stars_y']]\n",
    "bus_rev_users = pd.merge(businessReviews, user,on='user_id',right_index=True,sort=False)[['business_id', 'cool_x', 'funny_x', 'review_id', 'stars_x', 'text', 'useful_x', 'user_id', 'categories', 'stars_y', 'average_stars', 'cool_y', 'elite', 'fans', 'friends', 'name', 'review_count_y', 'yelping_since']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2927731\n",
      "2927731\n",
      "['business_id', 'cool', 'funny', 'review_id', 'stars_x', 'text', 'useful', 'user_id', 'categories', 'review_count', 'stars_y']\n",
      "['business_id', 'cool_x', 'funny_x', 'review_id', 'stars_x', 'text', 'useful_x', 'user_id', 'categories', 'stars_y', 'average_stars', 'cool_y', 'elite', 'fans', 'friends', 'name', 'review_count_y', 'yelping_since']\n"
     ]
    }
   ],
   "source": [
    "print(len(businessReviews))\n",
    "print(len(bus_rev_users))\n",
    "print(list(businessReviews))\n",
    "print(list(bus_rev_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the first feature model to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numCategoryReviews(businessReviews):\n",
    "    return businessReviews[['business_id','user_id']].groupby('user_id',as_index=False).count()\n",
    "\n",
    "def average_star_category_rating(businessReviews):\n",
    "    return businessReviews[['user_id','stars_x']].groupby('user_id',as_index=False).mean()\n",
    "\n",
    "def std_star_category_rating(businessReviews):\n",
    "    busRev = businessReviews[['user_id','stars_x']].groupby('user_id',as_index=False).agg(np.var)\n",
    "    busRev['stars_x'] = busRev['stars_x'].pow(1./2)\n",
    "    return busRev\n",
    "\n",
    "def funny_useful_cool(businessReviews):\n",
    "    return businessReviews[['user_id','funny','useful','cool']].groupby('user_id',as_index=False).sum()\n",
    "\n",
    "def months_yelping(businessReviews):\n",
    "    user_dates = businessReviews[['user_id','yelping_since']].drop_duplicates()\n",
    "    curr_date = datetime(2017,10,17)\n",
    "    uyelp_dates = [datetime.strptime(i, \"%Y-%m-%d\") for i in user_dates['yelping_since']]\n",
    "    months_yelping = [(curr_date.year - i.year) * 12 + curr_date.month - i.month for i in uyelp_dates]\n",
    "    user_dates['yelping_since'] = months_yelping\n",
    "    return user_dates\n",
    "\n",
    "def get_elite_users(df):\n",
    "    temp = []\n",
    "    for i in df['elite'].index.values:\n",
    "        if df['elite'][i]:\n",
    "            temp.append(i)\n",
    "    return temp, df.loc[temp]\n",
    "\n",
    "def feature1(df, df1):\n",
    "    tot_reviews = df1[['user_id','review_count_y']]\n",
    "    tot_reviews.columns = ['user_id','Total Reviews by User']\n",
    "    catRev = numCategoryReviews(df)\n",
    "    catRev.columns = ['user_id','Num Category Reviews']\n",
    "    averageCat = average_star_category_rating(df)\n",
    "    averageCat.columns = ['user_id','Average Rating in Category']\n",
    "    stdCat = std_star_category_rating(df)\n",
    "    stdCat.columns = ['user_id','Std Dev of Ratings in Category']\n",
    "    fuc = funny_useful_cool(df)\n",
    "    monthsYelp = months_yelping(df1)\n",
    "    monthsYelp.columns = ['user_id', 'Months Yelping']\n",
    "    is_elite = df1[['user_id','elite']]\n",
    "    features = tot_reviews.merge(catRev,on='user_id').merge(averageCat,on='user_id').merge(stdCat,on='user_id').merge(fuc,on='user_id').merge(monthsYelp,on='user_id').merge(is_elite,on='user_id')\n",
    "    features = features.drop_duplicates('user_id')\n",
    "    features.index = range(len(features))\n",
    "    elite_ind, elite_users = get_elite_users(features)\n",
    "    expertClassifier = [0]*len(feature_set_1)\n",
    "    for i in elite_ind:\n",
    "        expertClassifier[i]=1\n",
    "    features = pd.concat([features, pd.DataFrame(expertClassifier,columns=['is_elite'])],axis=1)\n",
    "    return features.fillna(0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "feature_set_1 = feature1(businessReviews, bus_rev_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Setups (Sklearn Library)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Runs the model specified by the clf (classifier), and features.\n",
    "Features is assumed to have an 'is_elite' column which gives the classifications'''\n",
    "def run_model(clf, features):\n",
    "    train, test = train_test_split(X)\n",
    "    train_classifier = train['is_elite'].values\n",
    "    test_classifier = test['is_elite'].values\n",
    "    train = train.drop('is_elite',axis=1)\n",
    "    test = test.drop('is_elite', axis=1)\n",
    "    clf.fit(train, train_classifier)\n",
    "    rf_pred = clf.predict(test)\n",
    "    model_perf= {'Model_Score' : clf.score(test, test_classifier),\n",
    "                'Predictions' : rf_pred,\n",
    "                'Prediction Probabilities' : clf.predict_proba(test),\n",
    "                'Total_Tested' : len(rf_pred),\n",
    "                'Num_Experts_Predicted' : sum(rf_pred),\n",
    "                'Num_Experts_Actual' : sum(test_classifier),\n",
    "                'Num_Experts_Training' : sum(train_classifier)} \n",
    "    return model_perf\n",
    "\n",
    "'''Runs the model n times, and prints out a dictionary with the statistics'''\n",
    "def bootstrap_model(clf, features, n):\n",
    "    models = []\n",
    "    for i in range(1,n):\n",
    "        models.append(run_model(clf, features))\n",
    "    return models\n",
    "\n",
    "'''Gets statistics from the bootstrap list of dictionaries'''\n",
    "def boot_statistics(models):\n",
    "    stats = []\n",
    "    expert_pred_percentage = [i['Num_Experts_Predicted']/i['Num_Experts_Actual'] for i in RF_bootstrap]\n",
    "    stats = expert_pred_percentage\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Drop unnessary columns from the features table (call it X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_set_1.drop('user_id',axis=1).drop('elite',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF = RandomForestClassifier(max_depth=3)\n",
    "run_model(clf_RF,X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF_bootstrap = bootstrap_model(clf_RF, X, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a gaussian naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_NB = GaussianNB()\n",
    "run_model(clf_NB,X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model_Score': 0.92866929019093425,\n",
       " 'Num_Experts_Actual': 12590,\n",
       " 'Num_Experts_Predicted': 9782,\n",
       " 'Num_Experts_Training': 38089,\n",
       " 'Prediction Probabilities': array([[ 1.        ,  0.        ],\n",
       "        [ 1.        ,  0.        ],\n",
       "        [ 0.99676898,  0.00323102],\n",
       "        ..., \n",
       "        [ 0.        ,  1.        ],\n",
       "        [ 0.98324022,  0.01675978],\n",
       "        [ 0.9787234 ,  0.0212766 ]]),\n",
       " 'Predictions': array([0, 0, 0, ..., 1, 0, 0]),\n",
       " 'Total_Tested': 205830}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_DT = tree.DecisionTreeClassifier()\n",
    "run_model(clf_DT, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
