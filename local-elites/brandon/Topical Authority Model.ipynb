{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topical Expert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Brandon/Yelp Dataset/Yelp-FA17/local-elites/brandon\n",
      "['.DS_Store', 'business.json', 'checkin.json', 'photos.json', 'review.json', 'review5000.json', 'tip.json', 'user.json', 'user5000.json']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.listdir('/Users/Brandon/Yelp Dataset/dataset'))\n",
    "import json\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from pandas import HDFStore,DataFrame\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_json_to_df(datapass):\n",
    "    '''\n",
    "    Load the json file and parse the file to pandas dataframe format\n",
    "    \n",
    "    Input:\n",
    "        datapass(str) : directory to the json file\n",
    "    Output:\n",
    "        df(dataframe) : pandas dataframe object\n",
    "    '''\n",
    "    \n",
    "    data = [] \n",
    "    with open(datapass) as data_file: \n",
    "        for f in data_file:\n",
    "            data.append(json.loads(f))\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 23.3 s, total: 1min 26s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import_file = \"/Users/Brandon/Yelp Dataset/dataset/review.json\"\n",
    "review = load_json_to_df(import_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.25 s, sys: 453 ms, total: 5.7 s\n",
      "Wall time: 6.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import_file = \"/Users/Brandon/Yelp Dataset/dataset/business.json\"\n",
    "business = load_json_to_df(import_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 s, sys: 17.5 s, total: 1min 10s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import_file = \"/Users/Brandon/Yelp Dataset/dataset/user.json\"\n",
    "user = load_json_to_df(import_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFind(df, cat):\n",
    "    return [cat in i for i in df['categories']]\n",
    "\n",
    "def category_counts(df):\n",
    "    all_cats = []\n",
    "    for i in df['categories']:\n",
    "        for j in i:\n",
    "            all_cats.append(j)\n",
    "    categories = set(all_cats)\n",
    "    category_counts = {}\n",
    "    for cat in categories:\n",
    "        category_counts[cat] = all_cats.count(cat)\n",
    "    return len(categories), category_counts\n",
    "\n",
    "def top_categories(counts, n):\n",
    "    top_categories = sorted(counts.keys(), key=(lambda k: counts[k]),reverse=True)[:n]\n",
    "    return top_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Restaurants',\n",
       " 'Shopping',\n",
       " 'Food',\n",
       " 'Beauty & Spas',\n",
       " 'Home Services',\n",
       " 'Health & Medical',\n",
       " 'Nightlife',\n",
       " 'Bars',\n",
       " 'Automotive',\n",
       " 'Local Services',\n",
       " 'Event Planning & Services',\n",
       " 'Active Life',\n",
       " 'Fashion',\n",
       " 'Sandwiches',\n",
       " 'Fast Food',\n",
       " 'American (Traditional)',\n",
       " 'Pizza',\n",
       " 'Coffee & Tea',\n",
       " 'Hair Salons',\n",
       " 'Hotels & Travel',\n",
       " 'Arts & Entertainment',\n",
       " 'Home & Garden',\n",
       " 'Auto Repair',\n",
       " 'Italian',\n",
       " 'Burgers',\n",
       " 'Doctors',\n",
       " 'Breakfast & Brunch',\n",
       " 'Mexican',\n",
       " 'Nail Salons',\n",
       " 'Professional Services',\n",
       " 'American (New)',\n",
       " 'Chinese',\n",
       " 'Real Estate',\n",
       " 'Specialty Food',\n",
       " 'Fitness & Instruction',\n",
       " 'Pets',\n",
       " 'Grocery',\n",
       " 'Bakeries',\n",
       " 'Cafes',\n",
       " 'Hair Removal',\n",
       " 'Dentists',\n",
       " 'Hotels',\n",
       " 'Desserts',\n",
       " 'Skin Care',\n",
       " \"Women's Clothing\",\n",
       " 'Education',\n",
       " 'Japanese',\n",
       " 'Ice Cream & Frozen Yogurt',\n",
       " 'Pet Services',\n",
       " 'Day Spas',\n",
       " 'Massage',\n",
       " 'General Dentistry',\n",
       " 'Financial Services',\n",
       " 'Pubs',\n",
       " 'Chicken Wings',\n",
       " 'Seafood',\n",
       " 'Contractors',\n",
       " 'Salad',\n",
       " 'Gyms',\n",
       " 'Sushi Bars',\n",
       " 'Sports Bars',\n",
       " 'Apartments',\n",
       " 'Caterers',\n",
       " 'Flowers & Gifts',\n",
       " 'Sporting Goods',\n",
       " 'Wine & Spirits',\n",
       " 'Beer',\n",
       " 'Cosmetics & Beauty Supply',\n",
       " 'Oil Change Stations',\n",
       " 'Tires',\n",
       " 'Accessories',\n",
       " 'Venues & Event Spaces',\n",
       " 'Delis',\n",
       " 'Hair Stylists',\n",
       " 'Asian Fusion',\n",
       " 'Barbers',\n",
       " 'Waxing',\n",
       " 'Mediterranean',\n",
       " 'Auto Parts & Supplies',\n",
       " 'Trainers',\n",
       " 'Car Dealers',\n",
       " 'Furniture Stores',\n",
       " 'Home Decor',\n",
       " 'Cosmetic Dentists',\n",
       " 'Drugstores',\n",
       " 'Barbeque',\n",
       " 'Department Stores',\n",
       " \"Men's Clothing\",\n",
       " 'Canadian (New)',\n",
       " 'Lounges',\n",
       " 'Arts & Crafts',\n",
       " 'Jewelry',\n",
       " 'Convenience Stores',\n",
       " 'Steakhouses',\n",
       " 'Thai',\n",
       " 'Indian',\n",
       " 'Juice Bars & Smoothies',\n",
       " 'Eyelash Service',\n",
       " 'Massage Therapy',\n",
       " 'Medical Centers']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cats, cat_counts = category_counts(business)\n",
    "top_cats = top_categories(cat_counts, 100)\n",
    "top_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 s, sys: 28.2 s, total: 1min 6s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "businessReviews = pd.merge(review, restaurants,on='business_id',right_index=True,sort=False)[['business_id', 'cool', 'funny', 'review_id', 'stars_x', 'text', 'useful', 'user_id', 'categories', 'review_count', 'stars_y']]\n",
    "bus_rev_users = pd.merge(businessReviews, user,on='user_id',right_index=True,sort=False)[['business_id', 'cool_x', 'funny_x', 'review_id', 'stars_x', 'text', 'useful_x', 'user_id', 'categories', 'stars_y', 'average_stars', 'cool_y', 'elite', 'fans', 'friends', 'name', 'review_count_y', 'yelping_since']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2927731\n",
      "2927731\n",
      "['business_id', 'cool', 'funny', 'review_id', 'stars_x', 'text', 'useful', 'user_id', 'categories', 'review_count', 'stars_y']\n",
      "['business_id', 'cool_x', 'funny_x', 'review_id', 'stars_x', 'text', 'useful_x', 'user_id', 'categories', 'stars_y', 'average_stars', 'cool_y', 'elite', 'fans', 'friends', 'name', 'review_count_y', 'yelping_since']\n"
     ]
    }
   ],
   "source": [
    "print(len(businessReviews))\n",
    "print(len(bus_rev_users))\n",
    "print(list(businessReviews))\n",
    "print(list(bus_rev_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction From Yelp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numCategoryReviews(businessReviews):\n",
    "    return businessReviews[['business_id','user_id']].groupby('user_id',as_index=False).count()\n",
    "\n",
    "def average_star_category_rating(businessReviews):\n",
    "    return businessReviews[['user_id','stars_x']].groupby('user_id',as_index=False).mean()\n",
    "\n",
    "def std_star_category_rating(businessReviews):\n",
    "    busRev = businessReviews[['user_id','stars_x']].groupby('user_id',as_index=False).agg(np.var)\n",
    "    busRev['stars_x'] = busRev['stars_x'].pow(1./2)\n",
    "    return busRev\n",
    "\n",
    "def funny_useful_cool(businessReviews):\n",
    "    return businessReviews[['user_id','funny','useful','cool']].groupby('user_id',as_index=False).sum()\n",
    "\n",
    "def months_yelping(businessReviews):\n",
    "    user_dates = businessReviews[['user_id','yelping_since']].drop_duplicates()\n",
    "    curr_date = datetime(2017,10,17)\n",
    "    uyelp_dates = [datetime.strptime(i, \"%Y-%m-%d\") for i in user_dates['yelping_since']]\n",
    "    months_yelping = [(curr_date.year - i.year) * 12 + curr_date.month - i.month for i in uyelp_dates]\n",
    "    user_dates['yelping_since'] = months_yelping\n",
    "    return user_dates\n",
    "\n",
    "def get_elite_users(df):\n",
    "    temp = []\n",
    "    for i in df['elite'].index.values:\n",
    "        if df['elite'][i]:\n",
    "            temp.append(i)\n",
    "    return temp, df.loc[temp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the first feature model to be analyzed\n",
    "Features: Total Reviews by User, Number of Category Reviews, Average Rating in Category, Std Dev of Ratings in Category, Funny, Useful, and Cool Votes, Number of Months since joining Yelp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature1(df, df1):\n",
    "    tot_reviews = df1[['user_id','review_count_y']]\n",
    "    tot_reviews.columns = ['user_id','Total Reviews by User']\n",
    "    catRev = numCategoryReviews(df)\n",
    "    catRev.columns = ['user_id','Num Category Reviews']\n",
    "    averageCat = average_star_category_rating(df)\n",
    "    averageCat.columns = ['user_id','Average Rating in Category']\n",
    "    stdCat = std_star_category_rating(df)\n",
    "    stdCat.columns = ['user_id','Std Dev of Ratings in Category']\n",
    "    fuc = funny_useful_cool(df)\n",
    "    monthsYelp = months_yelping(df1)\n",
    "    monthsYelp.columns = ['user_id', 'Months Yelping']\n",
    "    is_elite = df1[['user_id','elite']]\n",
    "    features = tot_reviews.merge(catRev,on='user_id').merge(averageCat,on='user_id').merge(stdCat,on='user_id').merge(fuc,on='user_id').merge(monthsYelp,on='user_id').merge(is_elite,on='user_id')\n",
    "    features = features.drop_duplicates('user_id')\n",
    "    features.index = range(len(features))\n",
    "    elite_ind, elite_users = get_elite_users(features)\n",
    "    expertClassifier = [0]*len(features)\n",
    "    for i in elite_ind:\n",
    "        expertClassifier[i]=1\n",
    "    features = pd.concat([features, pd.DataFrame(expertClassifier,columns=['is_expert'])],axis=1)\n",
    "    return features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 59.8 s, total: 2min 29s\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feature_set_1 = feature1(businessReviews, bus_rev_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823317\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Total Reviews by User</th>\n",
       "      <th>Num Category Reviews</th>\n",
       "      <th>Average Rating in Category</th>\n",
       "      <th>Std Dev of Ratings in Category</th>\n",
       "      <th>funny</th>\n",
       "      <th>useful</th>\n",
       "      <th>cool</th>\n",
       "      <th>Months Yelping</th>\n",
       "      <th>elite</th>\n",
       "      <th>is_expert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kzyLOqiJvyw_FWFTw2rjiQ</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WZXp9-V2dqRRJqhGgRqueA</td>\n",
       "      <td>327</td>\n",
       "      <td>44</td>\n",
       "      <td>3.477273</td>\n",
       "      <td>0.762146</td>\n",
       "      <td>42</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "      <td>61</td>\n",
       "      <td>[2016, 2015]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XylT12exfdLiI_3uDLVIpw</td>\n",
       "      <td>344</td>\n",
       "      <td>31</td>\n",
       "      <td>3.741935</td>\n",
       "      <td>1.504831</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>84</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ji9PeffxjwqPLO7pEfSpKQ</td>\n",
       "      <td>93</td>\n",
       "      <td>58</td>\n",
       "      <td>3.258621</td>\n",
       "      <td>1.101201</td>\n",
       "      <td>49</td>\n",
       "      <td>98</td>\n",
       "      <td>68</td>\n",
       "      <td>107</td>\n",
       "      <td>[2010, 2009]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TLIWzAJPrET0zX4_vgvLhg</td>\n",
       "      <td>53</td>\n",
       "      <td>19</td>\n",
       "      <td>3.631579</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id  Total Reviews by User  Num Category Reviews  \\\n",
       "0  kzyLOqiJvyw_FWFTw2rjiQ                      2                     2   \n",
       "1  WZXp9-V2dqRRJqhGgRqueA                    327                    44   \n",
       "2  XylT12exfdLiI_3uDLVIpw                    344                    31   \n",
       "3  Ji9PeffxjwqPLO7pEfSpKQ                     93                    58   \n",
       "4  TLIWzAJPrET0zX4_vgvLhg                     53                    19   \n",
       "\n",
       "   Average Rating in Category  Std Dev of Ratings in Category  funny  useful  \\\n",
       "0                    3.000000                        2.828427      0       0   \n",
       "1                    3.477273                        0.762146     42      54   \n",
       "2                    3.741935                        1.504831     11      32   \n",
       "3                    3.258621                        1.101201     49      98   \n",
       "4                    3.631579                        0.830698      1       4   \n",
       "\n",
       "   cool  Months Yelping         elite  is_expert  \n",
       "0     0              16            []          0  \n",
       "1    46              61  [2016, 2015]          1  \n",
       "2    13              84            []          0  \n",
       "3    68             107  [2010, 2009]          1  \n",
       "4     0              38            []          0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(feature_set_1))\n",
    "feature_set_1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Setups (Sklearn Library)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Runs the model specified by the clf (classifier), and features.\n",
    "Features is assumed to have an 'is_expert' column which gives the classifications'''\n",
    "def run_model(clf, features):\n",
    "    train, test = train_test_split(X)\n",
    "    train_classifier = train['is_expert'].values\n",
    "    test_classifier = test['is_expert'].values\n",
    "    train = train.drop('is_expert',axis=1)\n",
    "    test = test.drop('is_expert', axis=1)\n",
    "    clf.fit(train, train_classifier)\n",
    "    rf_pred = clf.predict(test)\n",
    "    model_perf= {'Model_Score' : clf.score(test, test_classifier),\n",
    "                'Predictions' : rf_pred,\n",
    "                'Prediction Probabilities' : clf.predict_proba(test),\n",
    "                'Total_Tested' : len(rf_pred),\n",
    "                'Num_Experts_Predicted' : sum(rf_pred),\n",
    "                'Num_Experts_Actual' : sum(test_classifier),\n",
    "                'Num_Experts_Training' : sum(train_classifier)} \n",
    "    return model_perf\n",
    "\n",
    "'''Runs the model n times, and prints out a dictionary with the statistics'''\n",
    "def bootstrap_model(clf, features, n):\n",
    "    models = []\n",
    "    for i in range(1,n):\n",
    "        models.append(run_model(clf, features))\n",
    "    return models\n",
    "\n",
    "'''Gets statistics from the bootstrap list of dictionaries'''\n",
    "def boot_statistics(models):\n",
    "    stats = []\n",
    "    expert_pred_percentage = [i['Num_Experts_Predicted']/i['Num_Experts_Actual'] for i in RF_bootstrap]\n",
    "    stats = expert_pred_percentage\n",
    "    return stats\n",
    "\n",
    "def graph_from_statistics(stats):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Drop unnessary columns from the features table (call it X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_set_1.drop('user_id',axis=1).drop('elite',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model_Score': 0.95621143662245545,\n",
       " 'Num_Experts_Actual': 12682,\n",
       " 'Num_Experts_Predicted': 6163,\n",
       " 'Num_Experts_Training': 37997,\n",
       " 'Prediction Probabilities': array([[ 0.98200494,  0.01799506],\n",
       "        [ 0.98457804,  0.01542196],\n",
       "        [ 0.98457804,  0.01542196],\n",
       "        ..., \n",
       "        [ 0.9379149 ,  0.0620851 ],\n",
       "        [ 0.98457804,  0.01542196],\n",
       "        [ 0.98457804,  0.01542196]]),\n",
       " 'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 'Total_Tested': 205830}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RF = RandomForestClassifier(max_depth=3)\n",
    "run_model(clf_RF,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_bootstrap = bootstrap_model(clf_RF, X, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Model_Score': 0.95601224311324884,\n",
       "  'Num_Experts_Actual': 12437,\n",
       "  'Num_Experts_Predicted': 5773,\n",
       "  'Num_Experts_Training': 38242,\n",
       "  'Prediction Probabilities': array([[ 0.46175546,  0.53824454],\n",
       "         [ 0.98377684,  0.01622316],\n",
       "         [ 0.9803217 ,  0.0196783 ],\n",
       "         ..., \n",
       "         [ 0.97055319,  0.02944681],\n",
       "         [ 0.98716111,  0.01283889],\n",
       "         [ 0.98716111,  0.01283889]]),\n",
       "  'Predictions': array([1, 0, 0, ..., 0, 0, 0]),\n",
       "  'Total_Tested': 205830},\n",
       " {'Model_Score': 0.9548850993538357,\n",
       "  'Num_Experts_Actual': 12637,\n",
       "  'Num_Experts_Predicted': 5815,\n",
       "  'Num_Experts_Training': 38042,\n",
       "  'Prediction Probabilities': array([[ 0.879875  ,  0.120125  ],\n",
       "         [ 0.85845812,  0.14154188],\n",
       "         [ 0.98607129,  0.01392871],\n",
       "         ..., \n",
       "         [ 0.98607129,  0.01392871],\n",
       "         [ 0.98607129,  0.01392871],\n",
       "         [ 0.94819677,  0.05180323]]),\n",
       "  'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "  'Total_Tested': 205830},\n",
       " {'Model_Score': 0.94835543895447705,\n",
       "  'Num_Experts_Actual': 12793,\n",
       "  'Num_Experts_Predicted': 3655,\n",
       "  'Num_Experts_Training': 37886,\n",
       "  'Prediction Probabilities': array([[ 0.96025048,  0.03974952],\n",
       "         [ 0.97990026,  0.02009974],\n",
       "         [ 0.47352169,  0.52647831],\n",
       "         ..., \n",
       "         [ 0.93644063,  0.06355937],\n",
       "         [ 0.97990026,  0.02009974],\n",
       "         [ 0.97990026,  0.02009974]]),\n",
       "  'Predictions': array([0, 0, 1, ..., 0, 0, 0]),\n",
       "  'Total_Tested': 205830},\n",
       " {'Model_Score': 0.95092066268279651,\n",
       "  'Num_Experts_Actual': 12679,\n",
       "  'Num_Experts_Predicted': 4187,\n",
       "  'Num_Experts_Training': 38000,\n",
       "  'Prediction Probabilities': array([[ 0.9680418 ,  0.0319582 ],\n",
       "         [ 0.98090343,  0.01909657],\n",
       "         [ 0.5091291 ,  0.4908709 ],\n",
       "         ..., \n",
       "         [ 0.98090343,  0.01909657],\n",
       "         [ 0.98090343,  0.01909657],\n",
       "         [ 0.97829485,  0.02170515]]),\n",
       "  'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "  'Total_Tested': 205830},\n",
       " {'Model_Score': 0.95764951659136177,\n",
       "  'Num_Experts_Actual': 12580,\n",
       "  'Num_Experts_Predicted': 6611,\n",
       "  'Num_Experts_Training': 38099,\n",
       "  'Prediction Probabilities': array([[ 0.97906186,  0.02093814],\n",
       "         [ 0.91000565,  0.08999435],\n",
       "         [ 0.98860024,  0.01139976],\n",
       "         ..., \n",
       "         [ 0.98329262,  0.01670738],\n",
       "         [ 0.97932245,  0.02067755],\n",
       "         [ 0.98860024,  0.01139976]]),\n",
       "  'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "  'Total_Tested': 205830},\n",
       " {'Model_Score': 0.95262595345673617,\n",
       "  'Num_Experts_Actual': 12770,\n",
       "  'Num_Experts_Predicted': 4855,\n",
       "  'Num_Experts_Training': 37909,\n",
       "  'Prediction Probabilities': array([[ 0.98705411,  0.01294589],\n",
       "         [ 0.98705411,  0.01294589],\n",
       "         [ 0.98705411,  0.01294589],\n",
       "         ..., \n",
       "         [ 0.984309  ,  0.015691  ],\n",
       "         [ 0.98172585,  0.01827415],\n",
       "         [ 0.98705411,  0.01294589]]),\n",
       "  'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "  'Total_Tested': 205830},\n",
       " {'Model_Score': 0.9537142301899626,\n",
       "  'Num_Experts_Actual': 12789,\n",
       "  'Num_Experts_Predicted': 5268,\n",
       "  'Num_Experts_Training': 37890,\n",
       "  'Prediction Probabilities': array([[ 0.97162524,  0.02837476],\n",
       "         [ 0.9691283 ,  0.0308717 ],\n",
       "         [ 0.92328454,  0.07671546],\n",
       "         ..., \n",
       "         [ 0.98177139,  0.01822861],\n",
       "         [ 0.95297921,  0.04702079],\n",
       "         [ 0.93169485,  0.06830515]]),\n",
       "  'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "  'Total_Tested': 205830},\n",
       " {'Model_Score': 0.95702764417237529,\n",
       "  'Num_Experts_Actual': 12590,\n",
       "  'Num_Experts_Predicted': 6619,\n",
       "  'Num_Experts_Training': 38089,\n",
       "  'Prediction Probabilities': array([[ 0.98597477,  0.01402523],\n",
       "         [ 0.98597477,  0.01402523],\n",
       "         [ 0.98695174,  0.01304826],\n",
       "         ..., \n",
       "         [ 0.98597477,  0.01402523],\n",
       "         [ 0.98597477,  0.01402523],\n",
       "         [ 0.97570754,  0.02429246]]),\n",
       "  'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "  'Total_Tested': 205830},\n",
       " {'Model_Score': 0.95900500412962153,\n",
       "  'Num_Experts_Actual': 12630,\n",
       "  'Num_Experts_Predicted': 7180,\n",
       "  'Num_Experts_Training': 38049,\n",
       "  'Prediction Probabilities': array([[ 0.98882085,  0.01117915],\n",
       "         [ 0.98882085,  0.01117915],\n",
       "         [ 0.97605991,  0.02394009],\n",
       "         ..., \n",
       "         [ 0.98882085,  0.01117915],\n",
       "         [ 0.98882085,  0.01117915],\n",
       "         [ 0.97053354,  0.02946646]]),\n",
       "  'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "  'Total_Tested': 205830}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a gaussian naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model_Score': 0.95621143662245545,\n",
       " 'Num_Experts_Actual': 12732,\n",
       " 'Num_Experts_Predicted': 8569,\n",
       " 'Num_Experts_Training': 37947,\n",
       " 'Prediction Probabilities': array([[  9.99999963e-01,   3.70040583e-08],\n",
       "        [  9.99999996e-01,   3.98915138e-09],\n",
       "        [  9.99999809e-01,   1.90917408e-07],\n",
       "        ..., \n",
       "        [  9.99999980e-01,   1.99553668e-08],\n",
       "        [  9.99999731e-01,   2.68650930e-07],\n",
       "        [  9.99999976e-01,   2.41525317e-08]]),\n",
       " 'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 'Total_Tested': 205830}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_NB = GaussianNB()\n",
    "run_model(clf_NB,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model_Score': 0.95333527668464269,\n",
       " 'Num_Experts_Actual': 12581,\n",
       " 'Num_Experts_Predicted': 12670,\n",
       " 'Num_Experts_Training': 38098,\n",
       " 'Prediction Probabilities': array([[ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.]]),\n",
       " 'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 'Total_Tested': 205830}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_DT = tree.DecisionTreeClassifier()\n",
    "run_model(clf_DT, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
