{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topical Expert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Brandon/Yelp Dataset/Yelp-FA17/local-elites/workspace\n",
      "['.DS_Store', 'business.json', 'checkin.json', 'photos.json', 'review.json', 'review5000.json', 'tip.json', 'user.json', 'user5000.json']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.listdir('/Users/Brandon/Yelp Dataset/dataset'))\n",
    "import json\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from pandas import HDFStore,DataFrame\n",
    "import operator\n",
    "import pylab as pl\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Copied from Kenta\n",
    "def load_json_to_df(datapass):\n",
    "    '''\n",
    "    Load the json file and parse the file to pandas dataframe format\n",
    "    \n",
    "    Input:\n",
    "        datapass(str) : directory to the json file\n",
    "    Output:\n",
    "        df(dataframe) : pandas dataframe object\n",
    "    '''\n",
    "    \n",
    "    data = [] \n",
    "    with open(datapass) as data_file: \n",
    "        for f in data_file:\n",
    "            data.append(json.loads(f))\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import_file = \"/Users/Brandon/Yelp Dataset/dataset/review.json\"\n",
    "review = load_json_to_df(import_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import_file = \"/Users/Brandon/Yelp Dataset/dataset/business.json\"\n",
    "business = load_json_to_df(import_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import_file = \"/Users/Brandon/Yelp Dataset/dataset/user.json\"\n",
    "user = load_json_to_df(import_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categoryFind(df, cat):\n",
    "    return [cat in i for i in df['categories']]\n",
    "\n",
    "def category_counts(df):\n",
    "    all_cats = []\n",
    "    for i in df['categories']:\n",
    "        for j in i:\n",
    "            all_cats.append(j)\n",
    "    categories = set(all_cats)\n",
    "    category_counts = {}\n",
    "    for cat in categories:\n",
    "        category_counts[cat] = all_cats.count(cat)\n",
    "    return len(categories), category_counts\n",
    "\n",
    "def top_categories(counts, n):\n",
    "    top_categories = sorted(counts.keys(), key=(lambda k: counts[k]),reverse=True)[:n]\n",
    "    return top_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cats, cat_counts = category_counts(business)\n",
    "top_cats = top_categories(cat_counts, 15)\n",
    "display(top_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "businessReviews = pd.merge(review, business,on='business_id',right_index=True,sort=False)[['business_id', 'cool', 'funny', 'review_id', 'stars_x', 'text', 'useful', 'user_id', 'categories', 'review_count', 'stars_y']]\n",
    "bus_rev_users = pd.merge(businessReviews, user,on='user_id',right_index=True,sort=False)[['business_id', 'cool_x', 'funny_x', 'review_id', 'stars_x', 'text', 'useful_x', 'user_id', 'categories', 'stars_y', 'average_stars', 'cool_y', 'elite', 'fans', 'friends', 'name', 'review_count_y', 'yelping_since']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(businessReviews))\n",
    "display(len(bus_rev_users))\n",
    "display(list(businessReviews))\n",
    "display(list(bus_rev_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction From Yelp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def category_choose(df, categories):\n",
    "    cats = np.array([True] * len(df['categories']))\n",
    "    for cat in categories:\n",
    "        cats= cats & np.array(categoryFind(df,cat))\n",
    "    return df[cats]\n",
    "\n",
    "def numCategoryReviews(businessReviews):\n",
    "    return businessReviews[['business_id','user_id']].groupby('user_id',as_index=False).count()\n",
    "\n",
    "def average_star_category_rating(businessReviews):\n",
    "    return businessReviews[['user_id','stars_x']].groupby('user_id',as_index=False).mean()\n",
    "\n",
    "def std_star_category_rating(businessReviews):\n",
    "    busRev = businessReviews[['user_id','stars_x']].groupby('user_id',as_index=False).agg(np.var)\n",
    "    busRev['stars_x'] = busRev['stars_x'].pow(1./2)\n",
    "    return busRev\n",
    "\n",
    "def funny_useful_cool(businessReviews):\n",
    "    return businessReviews[['user_id','funny','useful','cool']].groupby('user_id',as_index=False).sum()\n",
    "\n",
    "def months_yelping(businessReviews):\n",
    "    user_dates = businessReviews[['user_id','yelping_since']].drop_duplicates()\n",
    "    curr_date = datetime(2017,10,17)\n",
    "    uyelp_dates = [datetime.strptime(i, \"%Y-%m-%d\") for i in user_dates['yelping_since']]\n",
    "    months_yelping = [(curr_date.year - i.year) * 12 + curr_date.month - i.month for i in uyelp_dates]\n",
    "    user_dates['yelping_since'] = months_yelping\n",
    "    return user_dates\n",
    "\n",
    "def get_elite_users(df):\n",
    "    temp = []\n",
    "    for i in df['elite'].index.values:\n",
    "        if df['elite'][i]:\n",
    "            temp.append(i)\n",
    "    return temp, df.loc[temp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the first feature model to be analyzed\n",
    "Features: Total Reviews by User, Number of Category Reviews, Average Rating in Category, Std Dev of Ratings in Category, Funny, Useful, and Cool Votes, Number of Months since joining Yelp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature1(df, df1, categories):\n",
    "    if( not categories == \"All\"):\n",
    "        df = category_choose(df, categories)\n",
    "        df1 = category_choose(df1, categories)\n",
    "    tot_reviews = df1[['user_id','review_count_y']]\n",
    "    tot_reviews.columns = ['user_id','Total Reviews by User']\n",
    "    catRev = numCategoryReviews(df)\n",
    "    catRev.columns = ['user_id','Num Category Reviews']\n",
    "    averageCat = average_star_category_rating(df)\n",
    "    averageCat.columns = ['user_id','Average Rating in Category']\n",
    "    stdCat = std_star_category_rating(df)\n",
    "    stdCat.columns = ['user_id','Std Dev of Ratings in Category']\n",
    "    fuc = funny_useful_cool(df)\n",
    "    monthsYelp = months_yelping(df1)\n",
    "    monthsYelp.columns = ['user_id', 'Months Yelping']\n",
    "    is_elite = df1[['user_id','elite']]\n",
    "    features = tot_reviews.merge(catRev,on='user_id').merge(averageCat,on='user_id').merge(stdCat,on='user_id').merge(fuc,on='user_id').merge(monthsYelp,on='user_id').merge(is_elite,on='user_id')\n",
    "    features = features.drop_duplicates('user_id')\n",
    "    features.index = range(len(features))\n",
    "    elite_ind, elite_users = get_elite_users(features)\n",
    "    expertClassifier = [0]*len(features)\n",
    "    for i in elite_ind:\n",
    "        expertClassifier[i]=1\n",
    "    features = pd.concat([features, pd.DataFrame(expertClassifier,columns=['is_expert'])],axis=1)\n",
    "    return features.fillna(0)\n",
    "\n",
    "# Feature 2 has all of feature 1 plus the number of friends for each user\n",
    "def feature2(df, df1, categories, features1 = pd.DataFrame()):\n",
    "    if features1.empty:\n",
    "        features1= feature1(df,df1,categories)\n",
    "    \n",
    "    friends = pd.DataFrame([len(i) for i in df1['friends']], columns = ['Num_Friends'])\n",
    "    users = pd.DataFrame(df1['user_id'].values,columns=['user_id'])\n",
    "    num_friends = pd.concat([users, friends],axis=1)\n",
    "    features1= features1.merge(num_friends,on='user_id').drop_duplicates('user_id')\n",
    "    features1.index = range(len(features1))\n",
    "    return features1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Lets do places with categories Restaurant\n",
    "categories = ['Restaurants']\n",
    "feature_set_1 = feature1(businessReviews, bus_rev_users, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_2 = feature2(businessReviews, bus_rev_users, categories, feature_set_1)\n",
    "feature_set_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(len(feature_set_1))\n",
    "display(feature_set_1.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Setups (Sklearn Library)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Runs the model specified by the clf (classifier), and features.\n",
    "Features is assumed to have an 'is_expert' column which gives the classifications'''\n",
    "def run_model(clf, features):\n",
    "    train, test = train_test_split(X)\n",
    "    train_classifier = train['is_expert'].values\n",
    "    test_classifier = test['is_expert'].values\n",
    "    train = train.drop('is_expert',axis=1)\n",
    "    test = test.drop('is_expert', axis=1)\n",
    "    clf.fit(train, train_classifier)\n",
    "    rf_pred = clf.predict(test)\n",
    "    model_perf= {'Model_Score' : clf.score(test, test_classifier),\n",
    "                'Predictions' : rf_pred,\n",
    "                'Actual' : test_classifier,\n",
    "                'Prediction_Probabilities' : clf.predict_proba(test),\n",
    "                'Total_Tested' : len(rf_pred),\n",
    "                'Num_Experts_Predicted' : sum(rf_pred),\n",
    "                'Num_Experts_Actual' : sum(test_classifier),\n",
    "                'Num_Experts_Training' : sum(train_classifier)} \n",
    "    return model_perf\n",
    "\n",
    "'''Runs the model n times, and prints out a dictionary with the statistics'''\n",
    "def bootstrap_model(clf, features, n):\n",
    "    models = []\n",
    "    for i in range(1,n):\n",
    "        models.append(run_model(clf, features))\n",
    "    return models\n",
    "\n",
    "'''Gets statistics from the bootstrap list of dictionaries'''\n",
    "def boot_statistics(models):\n",
    "    stats = []\n",
    "    mean_model_score = np.mean([i['Model_Score'] for i in models])\n",
    "    expert_pred_percentage = [i['Num_Experts_Predicted']/i['Num_Experts_Actual'] for i in models]\n",
    "    mn = np.array((1.0 - np.array(mean_model_score))) * np.array(models[0]['Total_Tested'])\n",
    "    stats = {'Mean_Wrong_Predictions' : round(mn),\n",
    "             'Mean_Model_Score' : mean_model_score, \n",
    "             'Expert_Prediction_Percentage' : expert_pred_percentage}\n",
    "    return stats\n",
    "\n",
    "def graph_from_statistics(stats):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Drop unnessary columns from the features table (call it X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = feature_set_1.drop('user_id',axis=1).drop('elite',axis=1)\n",
    "X2 = feature_set_2.drop('user_id',axis=1).drop('elite',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Actual': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 'Model_Score': 0.95849001603264827,\n",
       " 'Num_Experts_Actual': 12563,\n",
       " 'Num_Experts_Predicted': 7007,\n",
       " 'Num_Experts_Training': 38116,\n",
       " 'Prediction_Probabilities': array([[ 0.98667353,  0.01332647],\n",
       "        [ 0.96662081,  0.03337919],\n",
       "        [ 0.98667353,  0.01332647],\n",
       "        ..., \n",
       "        [ 0.97008213,  0.02991787],\n",
       "        [ 0.97969029,  0.02030971],\n",
       "        [ 0.98667353,  0.01332647]]),\n",
       " 'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 'Total_Tested': 205830}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Actual': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 'Model_Score': 0.95146965942768302,\n",
       " 'Num_Experts_Actual': 12761,\n",
       " 'Num_Experts_Predicted': 4292,\n",
       " 'Num_Experts_Training': 37918,\n",
       " 'Prediction_Probabilities': array([[ 0.96834861,  0.03165139],\n",
       "        [ 0.97960301,  0.02039699],\n",
       "        [ 0.98208123,  0.01791877],\n",
       "        ..., \n",
       "        [ 0.97175066,  0.02824934],\n",
       "        [ 0.7813324 ,  0.2186676 ],\n",
       "        [ 0.97960301,  0.02039699]]),\n",
       " 'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 'Total_Tested': 205830}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_RF = RandomForestClassifier(max_depth=3)\n",
    "\n",
    "display(run_model(clf_RF,X))\n",
    "display(run_model(clf_RF,X2))\n",
    "\n",
    "RF_bootstrap = bootstrap_model(clf_RF, X, 10)\n",
    "RF2_bootstrap = bootstrap_model(clf_RF, X2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a gaussian naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Actual': array([0, 1, 0, ..., 0, 0, 0]),\n",
       " 'Model_Score': 0.9563960549968421,\n",
       " 'Num_Experts_Actual': 12577,\n",
       " 'Num_Experts_Predicted': 8350,\n",
       " 'Num_Experts_Training': 38102,\n",
       " 'Prediction_Probabilities': array([[  9.99999920e-01,   8.03111762e-08],\n",
       "        [  9.99999915e-01,   8.48009705e-08],\n",
       "        [  9.99999989e-01,   1.09528665e-08],\n",
       "        ..., \n",
       "        [  9.99999967e-01,   3.32475099e-08],\n",
       "        [  9.99999979e-01,   2.06560250e-08],\n",
       "        [  9.99998813e-01,   1.18724482e-06]]),\n",
       " 'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 'Total_Tested': 205830}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Actual': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 'Model_Score': 0.95621143662245545,\n",
       " 'Num_Experts_Actual': 12776,\n",
       " 'Num_Experts_Predicted': 8659,\n",
       " 'Num_Experts_Training': 37903,\n",
       " 'Prediction_Probabilities': array([[  9.99999964e-01,   3.56212067e-08],\n",
       "        [  9.99999988e-01,   1.22353807e-08],\n",
       "        [  1.00000000e+00,   2.62261638e-10],\n",
       "        ..., \n",
       "        [  9.99999976e-01,   2.42089574e-08],\n",
       "        [  9.99999990e-01,   9.57277537e-09],\n",
       "        [  9.99999722e-01,   2.77819398e-07]]),\n",
       " 'Predictions': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 'Total_Tested': 205830}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_NB = GaussianNB()\n",
    "\n",
    "display(run_model(clf_NB,X))\n",
    "display(run_model(clf_NB,X2))\n",
    "\n",
    "NB_bootstrap = bootstrap_model(clf_NB, X, 10)\n",
    "NB2_bootstrap = bootstrap_model(clf_NB, X2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Actual': array([0, 0, 1, ..., 0, 0, 0]),\n",
       " 'Model_Score': 0.95293203128795612,\n",
       " 'Num_Experts_Actual': 12558,\n",
       " 'Num_Experts_Predicted': 12830,\n",
       " 'Num_Experts_Training': 38121,\n",
       " 'Prediction_Probabilities': array([[ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        ..., \n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.]]),\n",
       " 'Predictions': array([0, 0, 1, ..., 0, 0, 0]),\n",
       " 'Total_Tested': 205830}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Actual': array([1, 0, 1, ..., 0, 0, 0]),\n",
       " 'Model_Score': 0.95283000534421614,\n",
       " 'Num_Experts_Actual': 12541,\n",
       " 'Num_Experts_Predicted': 12872,\n",
       " 'Num_Experts_Training': 38138,\n",
       " 'Prediction_Probabilities': array([[ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        ..., \n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.]]),\n",
       " 'Predictions': array([0, 0, 1, ..., 0, 0, 0]),\n",
       " 'Total_Tested': 205830}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_DT = tree.DecisionTreeClassifier()\n",
    "\n",
    "display(run_model(clf_DT, X))\n",
    "display(run_model(clf_DT, X2))\n",
    "\n",
    "DT_bootstrap = bootstrap_model(clf_DT, X, 10)\n",
    "DT2_bootstrap = bootstrap_model(clf_DT, X2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Expert_Prediction_Percentage': [1.0126333961079723,\n",
       "  1.0196440025657472,\n",
       "  1.0035957164074103,\n",
       "  1.0159069325735992,\n",
       "  1.0181314330958036,\n",
       "  1.0156262393908146,\n",
       "  0.99968592964824121,\n",
       "  0.99338908801274395,\n",
       "  1.0007049424297016],\n",
       " 'Mean_Model_Score': 0.95309883560867392,\n",
       " 'Mean_Wrong_Predictions': 9654.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Expert_Prediction_Percentage': [0.99945214056507792,\n",
       "  1.0129993658845911,\n",
       "  1.0096736138419189,\n",
       "  1.0210080677370397,\n",
       "  1.0300722050305482,\n",
       "  1.0324618908459047,\n",
       "  1.0099466857643034,\n",
       "  1.0007086056216046,\n",
       "  0.99462449361171701],\n",
       " 'Mean_Model_Score': 0.95285321759596642,\n",
       " 'Mean_Wrong_Predictions': 9704.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Expert_Prediction_Percentage': [0.68523964708687701,\n",
       "  0.68009758400881404,\n",
       "  0.67689015691868759,\n",
       "  0.67105263157894735,\n",
       "  0.66506136398943605,\n",
       "  0.66584727618745543,\n",
       "  0.67155949052500774,\n",
       "  0.66235175567785443,\n",
       "  0.66322297879001335],\n",
       " 'Mean_Model_Score': 0.95627621499943316,\n",
       " 'Mean_Wrong_Predictions': 9000.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Expert_Prediction_Percentage': [0.99945214056507792,\n",
       "  1.0129993658845911,\n",
       "  1.0096736138419189,\n",
       "  1.0210080677370397,\n",
       "  1.0300722050305482,\n",
       "  1.0324618908459047,\n",
       "  1.0099466857643034,\n",
       "  1.0007086056216046,\n",
       "  0.99462449361171701],\n",
       " 'Mean_Model_Score': 0.95285321759596642,\n",
       " 'Mean_Wrong_Predictions': 9704.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Expert_Prediction_Percentage': [0.52881595477386933,\n",
       "  0.50961014707026686,\n",
       "  0.30342014433636649,\n",
       "  0.26974358974358975,\n",
       "  0.29972451790633609,\n",
       "  0.31610614008022214,\n",
       "  0.32840399590969871,\n",
       "  0.25499244172169622,\n",
       "  0.41326327521694134],\n",
       " 'Mean_Model_Score': 0.95185455095089266,\n",
       " 'Mean_Wrong_Predictions': 9910.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Expert_Prediction_Percentage': [0.26514549212911431,\n",
       "  0.23381864219021997,\n",
       "  0.67774555146194249,\n",
       "  0.54040842072064965,\n",
       "  0.38357696301621536,\n",
       "  0.37549996078738923,\n",
       "  0.56350526899611764,\n",
       "  0.24940767651239931,\n",
       "  0.54004683840749412],\n",
       " 'Mean_Model_Score': 0.95418279378343507,\n",
       " 'Mean_Wrong_Predictions': 9431.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DT_stats = boot_statistics(DT_bootstrap)\n",
    "NB_stats = boot_statistics(NB_bootstrap)\n",
    "RF_stats = boot_statistics(RF_bootstrap)\n",
    "#\n",
    "DT2_stats = boot_statistics(DT2_bootstrap)\n",
    "NB2_stats = boot_statistics(NB2_bootstrap)\n",
    "RF2_stats = boot_statistics(RF2_bootstrap)\n",
    "\n",
    "display(DT_stats, DT2_stats)\n",
    "display(NB_stats, DT2_stats)\n",
    "display(RF_stats, RF2_stats)\n",
    "y = [DT_stats['Mean_Model_Score'],NB_stats['Mean_Model_Score'],RF_stats['Mean_Model_Score']]\n",
    "N = len(y)\n",
    "x = range(N)\n",
    "width = 1/1.5\n",
    "plt.bar(x, y, width)\n",
    "\n",
    "fig = plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "## Kmeans Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clf_KMeans = KMeans(n_clusters=2, random_state=0).fit(X2)\n",
    "display(clf_KMeans.labels_)\n",
    "\n",
    "kmeans_predictions = clf_KMeans.predict(X2)\n",
    "display(sum(clf_KMeans.predict(X2)))\n",
    "display(sum(1 - clf_KMeans.predict(X2)))\n",
    "display(clf_KMeans.cluster_centers_)\n",
    "\n",
    "clf_kmeans_2d = clf_KMeans.transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_KMeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_x = clf_kmeans_2d[:,0]\n",
    "kmeans_y = clf_kmeans_2d[:,1]\n",
    "plt.scatter(kmeans_x, kmeans_y, c=[matplotlib.cm.spectral(float(i) /10) for i in clf_KMeans.labels_]);   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "pca_2d = pca.transform(X)\n",
    "pca_x = pca_2d[:,0]\n",
    "pca_y = pca_2d[:,1]\n",
    "pl.scatter(pca_x, pca_y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_copy = X.assign(preds=pd.Series(kmeans_predictions).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sum(X_copy.is_expert))\n",
    "display(sum(X_copy.preds))\n",
    "display(sum(X_copy.is_expert & X_copy.preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
