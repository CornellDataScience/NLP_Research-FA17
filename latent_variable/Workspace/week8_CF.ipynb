{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "import seaborn as sns\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_json_to_df(datapass):\n",
    "    data = [] \n",
    "    with open(datapass) as data_file: \n",
    "        for f in data_file:\n",
    "            data.append(json.loads(f))\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = load_json_to_df(\"business.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review = load_json_to_df(\"review.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = load_json_to_df(\"user.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users_review = review.user_id.unique().shape[0]\n",
    "n_items_review = review.business_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group res by city\n",
    "city = business.groupby('city')['city'].count()\n",
    "city\n",
    "# subset restaurant to category restaurant\n",
    "#restaurant = business[business['categories'].str.contains(\"Restaurants\",na=False)]\n",
    "is_rest = []\n",
    "for i in business['categories']:\n",
    "    \n",
    "    if 'Restaurants' in i or 'Food' in i:\n",
    "        is_rest.append(True)\n",
    "    else:\n",
    "        is_rest.append(False)\n",
    "restaurant = business.loc[is_rest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "                 3\n",
       "110 Las Vegas    1\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city2 = restaurant.groupby('city')['city'].count()\n",
    "city.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2824 Milton Rd</td>\n",
       "      <td>{'GoodForMeal': {'dessert': False, 'latenight'...</td>\n",
       "      <td>mLwM-h2YhXl2NCgdS84_Bw</td>\n",
       "      <td>[Food, Soul Food, Convenience Stores, Restaura...</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>{'Monday': '10:00-22:00', 'Tuesday': '10:00-22...</td>\n",
       "      <td>0</td>\n",
       "      <td>35.236870</td>\n",
       "      <td>-80.741976</td>\n",
       "      <td>South Florida Style Chicken &amp; Ribs</td>\n",
       "      <td>Eastland</td>\n",
       "      <td>28215</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>337 Danforth Avenue</td>\n",
       "      <td>{'BusinessParking': {'garage': False, 'street'...</td>\n",
       "      <td>v2WhjAB3PIBA8J8VxG3wEg</td>\n",
       "      <td>[Food, Coffee &amp; Tea]</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>{'Monday': '10:00-19:00', 'Tuesday': '10:00-19...</td>\n",
       "      <td>0</td>\n",
       "      <td>43.677126</td>\n",
       "      <td>-79.353285</td>\n",
       "      <td>The Tea Emporium</td>\n",
       "      <td>Riverdale</td>\n",
       "      <td>M4K 1N7</td>\n",
       "      <td>7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               address                                         attributes  \\\n",
       "1       2824 Milton Rd  {'GoodForMeal': {'dessert': False, 'latenight'...   \n",
       "2  337 Danforth Avenue  {'BusinessParking': {'garage': False, 'street'...   \n",
       "\n",
       "              business_id                                         categories  \\\n",
       "1  mLwM-h2YhXl2NCgdS84_Bw  [Food, Soul Food, Convenience Stores, Restaura...   \n",
       "2  v2WhjAB3PIBA8J8VxG3wEg                               [Food, Coffee & Tea]   \n",
       "\n",
       "        city                                              hours  is_open  \\\n",
       "1  Charlotte  {'Monday': '10:00-22:00', 'Tuesday': '10:00-22...        0   \n",
       "2    Toronto  {'Monday': '10:00-19:00', 'Tuesday': '10:00-19...        0   \n",
       "\n",
       "    latitude  longitude                                name neighborhood  \\\n",
       "1  35.236870 -80.741976  South Florida Style Chicken & Ribs     Eastland   \n",
       "2  43.677126 -79.353285                    The Tea Emporium    Riverdale   \n",
       "\n",
       "  postal_code  review_count  stars state  \n",
       "1       28215             4    4.5    NC  \n",
       "2     M4K 1N7             7    4.5    ON  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2400 E Lake Mead Blvd</td>\n",
       "      <td>{'RestaurantsTableService': True, 'GoodForMeal...</td>\n",
       "      <td>LDMCrFlGIFUN6L-FEFgzWg</td>\n",
       "      <td>[Restaurants, American (Traditional), Mexican,...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>{'Monday': '9:00-23:00', 'Tuesday': '9:00-23:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>36.196203</td>\n",
       "      <td>-115.116799</td>\n",
       "      <td>El Pollo Loco</td>\n",
       "      <td></td>\n",
       "      <td>89030</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4190 S Rainbow Blvd</td>\n",
       "      <td>{'RestaurantsPriceRange2': 1, 'RestaurantsAtti...</td>\n",
       "      <td>QTH_XGh4rWYdd0fTW-tUDw</td>\n",
       "      <td>[Mexican, Restaurants]</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>36.112519</td>\n",
       "      <td>-115.242605</td>\n",
       "      <td>Baja Fresh Mexican Grill</td>\n",
       "      <td>Spring Valley</td>\n",
       "      <td>89103</td>\n",
       "      <td>7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  address                                         attributes  \\\n",
       "58  2400 E Lake Mead Blvd  {'RestaurantsTableService': True, 'GoodForMeal...   \n",
       "64    4190 S Rainbow Blvd  {'RestaurantsPriceRange2': 1, 'RestaurantsAtti...   \n",
       "\n",
       "               business_id                                         categories  \\\n",
       "58  LDMCrFlGIFUN6L-FEFgzWg  [Restaurants, American (Traditional), Mexican,...   \n",
       "64  QTH_XGh4rWYdd0fTW-tUDw                             [Mexican, Restaurants]   \n",
       "\n",
       "         city                                              hours  is_open  \\\n",
       "58  Las Vegas  {'Monday': '9:00-23:00', 'Tuesday': '9:00-23:0...        1   \n",
       "64  Las Vegas                                                 {}        0   \n",
       "\n",
       "     latitude   longitude                      name   neighborhood  \\\n",
       "58  36.196203 -115.116799             El Pollo Loco                  \n",
       "64  36.112519 -115.242605  Baja Fresh Mexican Grill  Spring Valley   \n",
       "\n",
       "   postal_code  review_count  stars state  \n",
       "58       89030            12    3.0    NV  \n",
       "64       89103             7    3.5    NV  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_vegas = restaurant.loc[restaurant['city']=='Las Vegas']\n",
    "res_vegas.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Left join restaruants in toronto table with review table\n",
    "review_rest_tor = pd.merge(res_vegas, review, on='business_id', how='left')\n",
    "# review_rest_tor.shape\n",
    "# review_rest_tor.columns\n",
    "\n",
    "# Subset to user, item, rating columns\n",
    "uir = review_rest_tor[['user_id','business_id','stars_y']]\n",
    "# len(uir)\n",
    "\n",
    "# Assign index for user and item\n",
    "user_index = uir.user_id.unique()\n",
    "item_index = uir.business_id.unique()\n",
    "\n",
    "# Count number of unique users and items\n",
    "n_users = uir.user_id.unique().shape[0]\n",
    "n_items = uir.business_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split User, Item, Rating dataset to train and test sets of 70% & 30%\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(uir, test_size=0.30, random_state=42)\n",
    "# len(train)\n",
    "# len(test)\n",
    "\n",
    "# Create table for train data with list of users as index & items as columns\n",
    "train_matrix = pd.DataFrame(index=user_index, columns=item_index)\n",
    "# train_matrix.shape\n",
    "\n",
    "# Fill in train_matrix table with ratings\n",
    "for row in train.itertuples():\n",
    "    user = row[1]\n",
    "    item = row[2]\n",
    "    train_matrix.loc[user][item] = row[3]  \n",
    "\n",
    "# Create table for test data with list of users as index & items as columns    \n",
    "test_matrix = pd.DataFrame(index=user_index, columns=item_index)\n",
    "# test_matrix.shape\n",
    "\n",
    "# Fill in test_matrix table with ratings\n",
    "for row in test.itertuples():\n",
    "    user = row[1]\n",
    "    item = row[2]\n",
    "    test_matrix.loc[user][item] = row[3]\n",
    "\n",
    "# Begin filtering process to create 5 Core Subset\n",
    "\n",
    "# Count number of rated items for each user\n",
    "item_1 = train_matrix.apply(lambda x: x > 0, raw=True).sum(axis=1)\n",
    "# item_1.value_counts()\n",
    "\n",
    "# Filter down to the users with greater than or equal to 5 ratings\n",
    "train1 = train_matrix\n",
    "train1['item_1'] = item_1\n",
    "train2 = train1.loc[train1['item_1'] >= 5]\n",
    "# train2.shape\n",
    "\n",
    "# Count number of rated users for each item\n",
    "train2 = train2.drop('item_1',axis=1)\n",
    "train3 = train2.transpose()\n",
    "user_1 = train3.apply(lambda x: x > 0, raw=True).sum(axis=1)\n",
    "# user_1.value_counts()\n",
    "\n",
    "# Filter down to the items with greater than or equal to 5 ratings\n",
    "train3['user_1'] = user_1\n",
    "train4 = train3.loc[train3['user_1'] >= 5]\n",
    "train4 = train4.drop('user_1',axis=1)\n",
    "train5 = train4.transpose()\n",
    "# train5.shape\n",
    "\n",
    "# Repeat the process for both user and item\n",
    "item_2 = train5.apply(lambda x: x > 0, raw=True).sum(axis=1)\n",
    "# item_2.value_counts()\n",
    "# item_2.shape\n",
    "train5['item_2'] = item_2\n",
    "train6 = train5.loc[train5['item_2'] >= 5]\n",
    "train6 = train6.drop('item_2',axis=1)\n",
    "train7 = train6.transpose()\n",
    "user_2 = train7.apply(lambda x: x > 0, raw=True).sum(axis=1)\n",
    "# user_2.value_counts()\n",
    "train7['user_2'] = user_2\n",
    "train8 = train7.loc[train7['user_2'] >= 5]\n",
    "train8 = train8.drop('user_2',axis=1)\n",
    "train9 = train8.transpose()\n",
    "# train9.shape\n",
    "\n",
    "# Check every user and item has at least 5 ratings\n",
    "item_3 = train9.apply(lambda x: x > 0, raw=True).sum(axis=1)\n",
    "# item_3.value_counts()\n",
    "user_3 = train9.apply(lambda x: x > 0, raw=True).sum(axis=1)\n",
    "# user_3.value_counts()\n",
    "\n",
    "# Filter down the test matrix to filtered user and item in train matrix\n",
    "test9 = test_matrix.loc[train9.index,train9.columns]\n",
    "# test9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print '\\nYelp Review Dataset'\n",
    "print 'Size of original Yelp dataset, Review is %s ' % str(review.shape)\n",
    "print 'Number of users is %s, number of items is %s ' % (str(n_users_review),str(n_items_review))\n",
    "print '\\nYelp Business Dataset'\n",
    "print 'Size of original Yelp dataset, Business is %s ' % str(business.shape)\n",
    "print 'Size of Restaurants subset of Business dataset is %s ' % str(restaurant.shape)\n",
    "print '\\nTop 10 Cities with the most number of restaurants are as follows \\n%s ' % str(city2.sort_values(ascending=False).head(10))\n",
    "print '\\nRestaurants in Toronto Subset'\n",
    "print 'Size of Restaurants in Toronto subset of Business dataset is %s ' % str(restaurant_toronto.shape)\n",
    "print 'User, Item, Rating dataset for restuarnats in Toronto contain %s rows ' % str(len(uir))\n",
    "print 'Number of users is %s, number of items is %s ' % (str(n_users),str(n_items))\n",
    "print '\\nRestaurants in Phoenix Subset'\n",
    "print 'Size of Restaurants in Phoenix subset of Business dataset is %s ' % str(restaurant_phoenix.shape)\n",
    "print 'User, Item, Rating dataset for restuarnats in Toronto contain %s rows ' % str(len(uir_ph))\n",
    "print 'Number of users is %s, number of items is %s ' % (str(n_users_ph),str(n_items_ph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print '\\nRestaurants in Toronto'\n",
    "print '\\nTrain dataset contains %s rows, Test dataset contains %s rows ' % (str(len(train)),str(len(test)))\n",
    "print 'Size of train & test matrices with users in rows & items in columns is %s ' % (str(train_matrix.shape))\n",
    "print '\\nUsers of filtered 5 core subset has rated at least 5 items as follows  \\n%s' % (str(item_3.value_counts().head(5)))\n",
    "print '\\nItems of filtered 5 core subset has been rated by at least 5 users as follows  \\n%s' % (str(user_3.value_counts().head(5)))\n",
    "print '\\nSize of 5 core subset is %s ' % (str(train9.shape))\n",
    "print '\\nRestaurants in Phoenix'\n",
    "print '\\nTrain dataset contains %s rows, Test dataset contains %s rows ' % (str(len(train_ph)),str(len(test_ph)))\n",
    "print 'Size of train & test matrices with users in rows & items in columns is %s ' % (str(train_matrix_ph.shape))\n",
    "print '\\nSize of 5 core subset is %s ' % (str(train9_ph.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collaborative_filtering(train, test, sim='cosine', type='user', knn=5):\n",
    "\n",
    "    # Fill NAN values in train & test data as 0's\n",
    "    train_0 = train.fillna(0)\n",
    "    test_0 = test.fillna(0)\n",
    "\n",
    "    # Create a similarity matrix of either users or items based on cosine or \n",
    "    # pearson correlation measure\n",
    "    if sim == 'cosine':\n",
    "        user_dist = pairwise_distances(train_0, metric='cosine')\n",
    "        item_dist = pairwise_distances(train_0.T, metric='cosine')\n",
    "\n",
    "    elif sim == 'pearson':\n",
    "        user_dist = pairwise_distances(train_0, metric='correlation')\n",
    "        item_dist = pairwise_distances(train_0.T, metric='correlation')\n",
    "        \n",
    "    user_sim = 1 - user_dist\n",
    "    item_sim = 1 - item_dist\n",
    " \n",
    "    # Create a dataframe with mean user ratings\n",
    "    mean_rating = train.mean(axis=1)\n",
    "    mean_user_rating = pd.concat([mean_rating] * len(train.columns), axis=1)\n",
    "    mean_user_rating.columns = train.columns\n",
    "    \n",
    "    # Modify a dataframe so that mean user ratings are present only in matrix \n",
    "    # positions of rated items and 0's in matrix positions of non-rated items\n",
    "    mean_user_rating_0 = mean_user_rating\n",
    "    mean_user_rating_0[train_0 == 0] = 0\n",
    "    \n",
    "    # Normalize every user's ratings to mean of zero\n",
    "    ratings_diff = train_0 - mean_user_rating_0\n",
    "    \n",
    "    # Create a dataframe with user's mean user ratings present in all items\n",
    "    mean_user_rating_f = pd.concat([mean_rating] * len(train.columns), axis=1)\n",
    "    mean_user_rating_f.columns = train.columns\n",
    "    \n",
    "    # Create a placeholder dataframe for predictions of rated items in test data\n",
    "    pred = pd.DataFrame(index=train.index, columns=train.columns)\n",
    "    \n",
    "    # User-Based Collaborative Filtering\n",
    "    if type == 'user':    \n",
    "        # Index user similarity matrix with user ids for both rows and columns\n",
    "        user_sim = pd.DataFrame(user_sim, index=train.index, columns=train.index)\n",
    "        # When the number of k neareast neighbors is specified\n",
    "        if knn != 'all':\n",
    "            user_sim_mat = user_sim.as_matrix()\n",
    "        \n",
    "            # Item id's of rated items in test data for each user\n",
    "            cols = test.columns\n",
    "            test_rated = test.apply(lambda x: x > 0, raw=True).apply(lambda x: list(cols[x.values]), axis=1)\n",
    "            \n",
    "            # Iterate over each user, m\n",
    "            for m in range(len(user_sim)):\n",
    "                # Retrieve column of user m's similarities to all other users\n",
    "                temp = user_sim_mat[m]\n",
    "                temp = pd.DataFrame(temp,index=train.index, columns=['similarity'])\n",
    "                # Rank user m's similarities\n",
    "                temp['rank'] = temp['similarity'].rank(ascending=0)\n",
    "                \n",
    "                # Iterate over user m's rated items\n",
    "                for n in range(len(test_rated[m])):\n",
    "                    # For user m's nth rated item, extract column of ratings of \n",
    "                    # all users corresponding to nth item\n",
    "                    temp2 = ratings_diff[[test_rated[m][n]]]\n",
    "                    temp2.columns = ['rating']\n",
    "                    # Contatenate similarity, rank, rating as one dataframe\n",
    "                    result = pd.concat([temp, temp2], axis=1)    \n",
    "                    # Filter down to the users who rated the items\n",
    "                    result2 = result[result['rating'] != 0]\n",
    "                    # Filter down to knn number of users with the knn \n",
    "                    # highest similairites\n",
    "                    result3 = result2.nsmallest(int(knn), 'rank')\n",
    "                \n",
    "                    # Divide weighted sum of user's knn nearest neighbors' ratings by \n",
    "                    # sum of their similarities\n",
    "                    score = result3['similarity'].dot(result3['rating'])/result3['similarity'].sum()\n",
    "                    mean = mean_user_rating_f.loc[train.index[m]][test_rated[m][n]]\n",
    "                \n",
    "                    # Make a prediction by adding user's mean rating to weighted sum\n",
    "                    pred.loc[train.index[m]][test_rated[m][n]] = mean + score\n",
    "                    \n",
    "        # When the number of k neareast neighbors is not specified and all \n",
    "        # available neighbors are used for prediction     \n",
    "        elif knn == 'all':  \n",
    "            # Compute user similarity weighted sum of available ratings of \n",
    "            # user's every neighbor \n",
    "            num_user = user_sim.dot(ratings_diff)\n",
    "            \n",
    "            # Sum user similarities    \n",
    "            sum_sim_user = user_sim.sum(axis=1)\n",
    "            sum_sim_mat_user = pd.concat([sum_sim_user] * len(train.columns), axis=1)\n",
    "            sum_sim_mat_user.columns = train.columns\n",
    "\n",
    "            # Create a dataframe of predictions computed by adding mean user \n",
    "            # rating to user similairty weighted sum of user's ratings \n",
    "            # divided by sum of user similarities\n",
    "            pred = mean_user_rating_f + num_user / sum_sim_mat_user\n",
    "                \n",
    "    # Item-Based Collaborative Filtering  \n",
    "    elif type == 'item':\n",
    "        # Index item similarity matrix with item ids for both rows and columns\n",
    "        item_sim = pd.DataFrame(item_sim, index=train.columns, columns=train.columns)\n",
    "        \n",
    "        # When the number of k neareast neighbors is specified\n",
    "        if knn != 'all':\n",
    "            item_sim_mat = item_sim.as_matrix()\n",
    "\n",
    "            # User id's of rated items in test data for each item\n",
    "            cols2 = test.T.columns\n",
    "            test_rated2 = test.T.apply(lambda x: x > 0, raw=True).apply(lambda x: list(cols2[x.values]), axis=1)\n",
    "        \n",
    "            # Iterate over each item, m\n",
    "            for m in range(len(item_sim)):\n",
    "                # Retrieve column of item m's similarities to all other items\n",
    "                temp = item_sim_mat[m]\n",
    "                temp = pd.DataFrame(temp,index=train.columns, columns=['similarity'])\n",
    "                # Rank item m's similarities\n",
    "                temp['rank'] = temp['similarity'].rank(ascending=0)\n",
    "\n",
    "                # Iterate over item m's rated users\n",
    "                for n in range(len(test_rated2[m])):\n",
    "                    # For item m's nth rated user, extract column of ratings of \n",
    "                    # all items corresponding to nth user\n",
    "                    temp2 = ratings_diff.T[[test_rated2[m][n]]]\n",
    "                    temp2.columns = ['rating']\n",
    "                    # Contatenate similarity, rank, rating as one dataframe\n",
    "                    result = pd.concat([temp, temp2], axis=1)    \n",
    "                    # Filter down to the items that are rated by the user\n",
    "                    result2 = result[result['rating'] != 0]\n",
    "                    # Filter down to knn number of items with the knn \n",
    "                    # highest similairites\n",
    "                    result3 = result2.nsmallest(int(knn), 'rank')\n",
    "                \n",
    "                    # Divide weighted sum of item's knn nearest neighbors' \n",
    "                    # ratings by sum of their similarities\n",
    "                    score = result3['similarity'].dot(result3['rating'])/result3['similarity'].sum()\n",
    "                    mean = mean_user_rating_f.loc[test_rated2[m][n]][train.columns[m]]\n",
    "                \n",
    "                    # Make a prediction by adding user's mean rating to weighted sum\n",
    "                    pred.loc[test_rated2[m][n]][train.columns[m]] = mean + score\n",
    "        \n",
    "        # When the number of k neareast neighbors is not specified and \n",
    "        # all available neighbors are used for prediction\n",
    "        elif knn == 'all':\n",
    "            # Compute item similarity weighted sum of available ratings of \n",
    "            # item's every neighbor\n",
    "            num_item = ratings_diff.dot(item_sim)\n",
    "\n",
    "            # Sum item similarities \n",
    "            sum_sim_item = item_sim.sum(axis=1)\n",
    "            sum_sim_item = pd.DataFrame(sum_sim_item, index=train.columns)\n",
    "            sum_sim_mat_item = pd.concat([sum_sim_item.T] * len(train), axis=0)\n",
    "\n",
    "            sum_sim_mat_item.index = train.index\n",
    "\n",
    "            # Create a dataframe of predictions computed by adding mean user \n",
    "            # rating to item similairty weighted sum of items' ratings \n",
    "            # divided by sum of item similarities\n",
    "            pred = mean_user_rating_f + num_item / sum_sim_mat_item\n",
    "            \n",
    "    pred_0 = pred.fillna(0)\n",
    "    pred_0_mat = pred_0.as_matrix()            \n",
    "    return pred_0_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test9_0 = test9.fillna(0)\n",
    "test9_0_mat = test9_0.as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "def mae(prediction, actual):\n",
    "    prediction = prediction[actual.nonzero()].flatten() \n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_absolute_error(prediction, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pred_user_5 = collaborative_filtering(train9, test9, sim='cosine', type='user', knn='5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
