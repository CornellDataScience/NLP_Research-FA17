{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"documenttop1_text_list.txt\", \"rb\") as f:\n",
    "    document_top1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "neg = list(opinion_lexicon.negative())\n",
    "pos = list(opinion_lexicon.positive())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert documents list to string\n",
    "doc = ''.join(document_top1)\n",
    "tokens = tokenizer.tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove stop words from tokens\n",
    "stopped_tokens = [i for i in tokens if not i in en_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "# stem token\n",
    "texts = [p_stemmer.stem(i) for i in stopped_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "neg = list(opinion_lexicon.negative())\n",
    "pos = list(opinion_lexicon.positive())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def of adding codeword\n",
    "def codeword(words):\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in pos:\n",
    "            words.insert(i+1, \"GOODREVIEW\")\n",
    "        if words[i] in neg:\n",
    "            words.insert(i+1, \"NEGREVIEW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codeword(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chic',\n",
       " 'GOODREVIEW',\n",
       " 'although',\n",
       " 'menu',\n",
       " 'item',\n",
       " 'doesnt',\n",
       " 'scream',\n",
       " 'NEGREVIEW',\n",
       " 'french',\n",
       " 'cuisin',\n",
       " 'most',\n",
       " 'food',\n",
       " 'look',\n",
       " 'like',\n",
       " 'GOODREVIEW',\n",
       " 'can',\n",
       " 'get',\n",
       " 'american',\n",
       " 'place',\n",
       " 'the',\n",
       " 'food',\n",
       " 'awesom',\n",
       " 'though',\n",
       " 'one',\n",
       " 'place',\n",
       " 'I',\n",
       " 'actual',\n",
       " 'come',\n",
       " 'satisfi',\n",
       " 'I',\n",
       " 'order',\n",
       " 'smoke',\n",
       " 'NEGREVIEW',\n",
       " 'salmon',\n",
       " 'platter',\n",
       " 'I',\n",
       " 'enjoy',\n",
       " 'GOODREVIEW',\n",
       " 'I',\n",
       " 'enjoy',\n",
       " 'GOODREVIEW',\n",
       " 'simpl',\n",
       " 'food',\n",
       " 'My',\n",
       " 'plate',\n",
       " 'shred',\n",
       " 'salmon',\n",
       " 'pile',\n",
       " 'caper']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "no_features = 1000\n",
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=no_features,\n",
    "                                   stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(texts)\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_features=no_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(texts)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "type(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "no_top_words = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "no_topics = 10\n",
    "\n",
    "# # Run NMF\n",
    "# nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "\n",
    "# # Run LDA\n",
    "lda_codeword = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "food just love tri mon amaz experi ask say baguett sandwich awesom said potato entre howev seafood qualiti super waffl usual actual told choic kind au fish wish goat list blueberri high thank crowd new 20 95 hous close immedi wouldn famili ye entir twice plu quick min girl style\n",
      "Topic 1:\n",
      "steak order restaur come bread ami soup star pari minut chicken benedict perfectli attent cream beauti absolut hour larg cours birthday veri request help mushroom return select bite bake let okay piec manag total bistro season stay won die quickli green slice wow franc real prefer mean recent juici mouss\n",
      "Topic 2:\n",
      "servic patio fountain frite make want onion salad butter cook look water warm start toast trip mignon busi coffe mani bacon tender street highli wife mussel year 15 abl differ brought pate gluten item fine impress extrem coupl second prepar late appl eaten pack care bf classic creami cake pay\n",
      "Topic 3:\n",
      "negreview great like price chees insid better scallop escargot special sure know need waitress crispi light quit share anoth ate mayb corn quich surpris lobster lemon given yum pancak later guess accommod brule pomm ribey promptli bone chef 11 cauliflow someon rush snail chanc popular afternoon 40 mom pure chewi\n",
      "Topic 4:\n",
      "goodreview menu room face platter doesn simpl begin air wa crusti play alright mostli elsewher horribl mood caus 18 shade deliv rang soak balanc pleasantli vacat man dim fare summer bother bouchon refresh meet hollandais occas read non complain martini allow complaint sidewalk confit monsieur futur miss uniqu frise certainli\n",
      "Topic 5:\n",
      "view realli nice outsid got best sit eat definit brunch wine didn day pretti dine crepe waiter wasn think outdoor atmospher tasti review spot took lot area group boyfriend yummi option bloodi mari morn melt indoor far cool includ gener expens complimentari refil opt dark mind near complaint note ad\n",
      "Topic 6:\n",
      "bellagio tabl dinner strip peopl recommend server lunch flavor salmon locat favorit worth everi disappoint walk fantast portion hotel parti ll noth glass cut check brie arriv thought rare merlot big everyon point especi yelp 30 meat chocol red hard open anyth couldn casino heat shrimp set burger rememb poivr\n",
      "Topic 7:\n",
      "vega time wait sauc enjoy littl alway went night filet everyth sinc way staff bad feel ambianc husband medium sweet hot 10 cold person garlic half els oh finish earli oyster spinach banana size suggest ice cocktail town hope brown wrong sever dri tip whip bottl smoke past croqu window\n",
      "Topic 8:\n",
      "good seat came reserv breakfast ve egg fri right serv tast thing appet dessert wonder overal sat end someth free away ok romant line happi main mouth caramel left white sunday hand averag creme consid work date dress omelett extra fact consist buffet roast unfortun hit turn world roll oliv\n",
      "Topic 9:\n",
      "place french delici gabi meal perfect thi friend watch excel dish don fresh bit la reason visit friendli expect drink long beef plate decid bar probabl hash huge small hostess stop offer use chip decent gave felt salti bring weekend instead final fan poach incred soft tomato miss weather tourist\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda_codeword, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
