{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalizing text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "import pickle\n",
    "import gensim\n",
    "from itertools import chain\n",
    "from gensim_lda_model import Gensimembedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load file\n",
    "business = pd.read_csv('chinese_business_clean.csv')\n",
    "reviews = pd.read_csv('chinese_reviews_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda =  models.LdaModel.load('gensim/lda.model')\n",
    "dictionary = corpora.Dictionary.load('gensim/chinsese_dict.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Gensimembedder(model = lda, dictionary = dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]\n",
    "\n",
    "def embed(text, model, dictionary):\n",
    "    text = tokenize(text)\n",
    "    bow = dictionary.doc2bow(text)\n",
    "    kindex = model.get_document_topics(bow, minimum_probability = 0.0)\n",
    "    out = [0] * model.num_topics\n",
    "    for i, p in kindex:\n",
    "        out[i] = p\n",
    "    return np.array(out) \n",
    "\n",
    "def embed_sent(text, model, dictionary, sent_length = False):\n",
    "    out = np.array([0.]*128)\n",
    "    sentences = len(nltk.sent_tokenize(text))\n",
    "    for text in nltk.sent_tokenize(text):\n",
    "        out += embed(text, lda, dictionary)\n",
    "    if sent_length:\n",
    "        return out/sentences, sentences\n",
    "    return (out/sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24136</th>\n",
       "      <td>CxDOIDnH8gp9KXzpBHJYXw</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27171</th>\n",
       "      <td>EiP1OFgs-XGcKZux0OKWIA</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>2e5V6M4GNufEnbGJpVdCjw</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user_id  business_id  cool  date  funny  review_id  \\\n",
       "24136  CxDOIDnH8gp9KXzpBHJYXw          528   528   528    528        528   \n",
       "27171  EiP1OFgs-XGcKZux0OKWIA          189   189   189    189        189   \n",
       "6341   2e5V6M4GNufEnbGJpVdCjw          142   142   142    142        142   \n",
       "\n",
       "       stars  text  useful  \n",
       "24136    528   528     528  \n",
       "27171    189   189     189  \n",
       "6341     142   142     142  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top users\n",
    "reviews.groupby('user_id').count().reset_index().sort_values(by = 'review_id', ascending = False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user1 = reviews[reviews['user_id'] == 'CxDOIDnH8gp9KXzpBHJYXw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vince Seafood Restaurant & BBQ has one of the most value in weekday dim sum offering around on a weekday morning! Before 11 am, it is 10% off $2.28  S/M/L size and free tea.\\n\\nNot surprisingly that it was packed with seniors that ordering a lot food to take out for lunch and dinner later to enjoy.\\n\\nDim Sum menu is quite interesting with a mix of classical and chiu chow style dim sum. And at this price point, my Yelp friend ordered quite a few and more from the menu.\\n \\nShrimp Dumpling \"Har Gow\" - A-OK\\nPork Dumpling with Liver on Top \"Siu Mai\" - Meh, not crazy about overcooked liver\\nPork Rib with Black Bean and Olive Sauce - good portion \\nBean Curd Skin Roll with Mix Chinese Vegetable - lacking filling\\nDumpling in Lotus Leaf - love this! great contrast of taste and texture! \\nBeef Tender in Spicy Sauce - Tender enough but really lacking any spice, more on the sweet side\\nCrystal Dumplings in Fish Papaya Soup - huge dumplings!!! shrimp has great bite!\\nRoast Pork Belly Roll - Not fatty enough and a little dry\\nRice Roll with Whole Shrimp - shrimp quite mushy and rice roll itself a little too thin\\n\\nOverall the quality and quantity are great! A little mix up here and there but service is friendly and decent.\\n\\nMy Yelp friend wants to try the Steamed Fish Intestine Egg Custard... I guess have to come back another time for that!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1['text'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. get_document_topics function in gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.13152346,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.24086614,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.62037661,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed(user1['text'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. sentence tokenize before embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V_{t} = \\frac{1}{s}\\sum_{s \\in \\text{sentences}} embed(s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.05784255,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.05784255,  0.        ,\n",
       "        0.        ,  0.        ,  0.00640918,  0.05580751,  0.        ,\n",
       "        0.        ,  0.        ,  0.00899581,  0.        ,  0.        ,\n",
       "        0.00903655,  0.08504895,  0.01107164,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.04915021,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.06165865,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.06420272,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.04510536,  0.00772431,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.04085461,  0.        ,\n",
       "        0.06530364,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.02525116,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01423182,  0.        ,  0.19212777,\n",
       "        0.00869844,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed_sent(user1['text'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Augemented Frequency to normalize sentence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V_{t}(doc) = \\alpha + \\alpha * \\frac{embed_{t}}{max(embed_{t}:t \\in d)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augmented_embed_sent(text, model, dictionary, alpha = 0.5):\n",
    "    out = np.array([0.]*128)\n",
    "    sentences = len(nltk.sent_tokenize(text))\n",
    "    for text in nltk.sent_tokenize(text):\n",
    "        out += embed(text, lda, dictionary)\n",
    "    \n",
    "    out = alpha + alpha * out/max(out)\n",
    "    \n",
    "    return out/sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00750733,  0.00750733,  0.01011315,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.01011315,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00779539,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00791543,  0.00750733,  0.00750733,\n",
       "        0.00791586,  0.01134502,  0.008001  ,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00972391,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.01028687,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.01117768,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.00784335,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00954575,  0.00799417,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.01048541,  0.00750733,\n",
       "        0.01045442,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.0106659 ,  0.00750733,  0.01491926,\n",
       "        0.00789786,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733,  0.00750733,  0.00750733,\n",
       "        0.00750733,  0.00750733,  0.00750733])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_embed_sent(user1['text'].values[0], model, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Personal tf-idf - most characteristic topic for particular user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$idf(t,D) = log\\frac{N}{|{d \\in D : t \\in d}|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_idf(df, model, dictionary, log = True):\n",
    "    freq = np.array([0.]*128)\n",
    "    s_count = 0\n",
    "    for d in df['text']:\n",
    "        x, s = embed_sent(d, model, dictionary, sent_length = True)\n",
    "        freq += np.ceil(x - min(x))\n",
    "        s_count += s\n",
    "    # add small value to avoid division by 0\n",
    "    freq += 1e-07\n",
    "    freq = s_count/freq\n",
    "    if log:\n",
    "        freq = np.log(freq)\n",
    "    # this happend when all sentences contain one common topic\n",
    "    # prones to happen when user writes few reviews\n",
    "    freq[np.where(freq < 0.0)] = 0.0\n",
    "    # pad topic that never used by this user\n",
    "    freq[np.where(np.log(s_count/1e-07) == freq)] = 0.0\n",
    "    return np.array(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.09104245,  3.37872452,  1.04874046,  2.97325941,  1.5777484 ,\n",
       "        2.2617631 ,  2.07944154,  2.8678989 ,  1.02207221,  2.74273576,\n",
       "        3.27336401,  2.63151012,  2.04958858,  1.87464713,  2.19155884,\n",
       "        1.70474809,  2.93689177,  2.44045489,  2.19155884,  2.37727598,\n",
       "        1.19392247,  1.33462235,  2.31785256,  2.07944154,  2.04958858,\n",
       "        3.871201  ,  2.2617631 ,  1.92529086,  2.93689177,  1.63436729,\n",
       "        5.17048396,  2.80336038,  2.83510908,  3.70414692,  1.86237704,\n",
       "        3.871201  ,  1.71521939,  2.03498978,  2.1419619 ,  2.74273576,\n",
       "        1.38629436,  3.22457384,  2.93689177,  4.4773368 ,  2.58021683,\n",
       "        2.41894868,  1.26514998,  1.22567117,  3.37872452,  3.09104245,\n",
       "        1.64412347,  1.85025567,  0.52930337,  1.41706602,  1.96503119,\n",
       "        3.56104608,  2.65817837,  2.53142666,  2.83510908,  2.97325941,\n",
       "        3.01099974,  1.79175947,  1.63436729,  3.27336401,  2.68557734,\n",
       "        1.75823678,  2.33727065,  2.1419619 ,  1.59626745,  2.07944154,\n",
       "        2.03498978,  2.90180045,  2.65817837,  2.44045489,  3.37872452,\n",
       "        0.98589255,  2.80336038,  1.61513593,  3.09104245,  2.02060104,\n",
       "        2.1419619 ,  3.871201  ,  4.4773368 ,  2.37727598,  2.35707328,\n",
       "        2.65817837,  4.65965835,  2.31785256,  3.13360206,  2.83510908,\n",
       "        5.17048396,  3.27336401,  3.01099974,  3.43588293,  2.63151012,\n",
       "        2.97325941,  2.97325941,  1.93836294,  2.83510908,  4.18965473,\n",
       "        2.31785256,  2.07944154,  3.01099974,  2.80336038,  2.8678989 ,\n",
       "        2.58021683,  3.17805383,  2.58021683,  2.77258872,  1.78045991,\n",
       "        4.0718717 ,  3.70414692,  2.33727065,  4.32318612,  0.88919893,\n",
       "        2.33727065,  2.17475172,  2.33727065,  1.46507524,  3.13360206,\n",
       "        3.37872452,  1.75823678,  2.09470901,  2.80336038,  3.27336401,\n",
       "        2.58021683,  2.71374822,  2.93689177])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_idf(user1, model, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_tfidf_embed(text, df, model, dictionary, alpha = 0.5):\n",
    "    tf = augmented_embed_sent(text, model, dictionary)\n",
    "    idf = user_idf(df,model,dictionary)\n",
    "    out = np.multiply(tf, idf)\n",
    "    return out/sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00866581,  0.01084059,  0.00442297,  0.00846665,  0.00460409,\n",
       "        0.00686505,  0.00616505,  0.00827994,  0.00444582,  0.00793827,\n",
       "        0.00935805,  0.00856457,  0.00628035,  0.00741363,  0.00639666,\n",
       "        0.00493936,  0.00899192,  0.00797763,  0.00659583,  0.00692194,\n",
       "        0.00404757,  0.00666485,  0.00761704,  0.00709939,  0.00639666,\n",
       "        0.01130094,  0.00670062,  0.00744276,  0.00837183,  0.00493936,\n",
       "        0.01458179,  0.00785863,  0.00910905,  0.01337093,  0.00567303,\n",
       "        0.0110619 ,  0.00525072,  0.0061208 ,  0.00630185,  0.00846665,\n",
       "        0.00622713,  0.00992861,  0.00899192,  0.01184542,  0.00763171,\n",
       "        0.00692194,  0.0060888 ,  0.0035842 ,  0.0094908 ,  0.0094908 ,\n",
       "        0.00627243,  0.00548976,  0.00151422,  0.00409506,  0.00538496,\n",
       "        0.01044182,  0.00770545,  0.00735371,  0.00899192,  0.00923096,\n",
       "        0.00877061,  0.00521808,  0.00506004,  0.0094908 ,  0.00819079,\n",
       "        0.00535083,  0.00709939,  0.00893716,  0.00529875,  0.0061208 ,\n",
       "        0.0061208 ,  0.00827994,  0.00802009,  0.01056273,  0.00910905,\n",
       "        0.00438413,  0.00827994,  0.00490994,  0.00910905,  0.00620995,\n",
       "        0.00670062,  0.01009008,  0.01216006,  0.00649458,  0.00703906,\n",
       "        0.00819079,  0.01337093,  0.00634888,  0.00935805,  0.00887921,\n",
       "        0.01544091,  0.00923096,  0.00837183,  0.00977543,  0.00778106,\n",
       "        0.00877061,  0.00856457,  0.00574961,  0.00887921,  0.01156079,\n",
       "        0.00716097,  0.00607721,  0.00962973,  0.00785863,  0.00846665,\n",
       "        0.00778106,  0.00887921,  0.00763171,  0.00846665,  0.00545442,\n",
       "        0.01216006,  0.01084059,  0.00812934,  0.01291058,  0.00518807,\n",
       "        0.00749091,  0.00644522,  0.00709939,  0.00447479,  0.00887921,\n",
       "        0.00962973,  0.00535083,  0.00616505,  0.00802009,  0.00977543,\n",
       "        0.00735371,  0.00709939,  0.00910905])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tfidf_embed(user1['text'].values[0], user1, model, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Personal tf * Business idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def business_idf(df, model, dictionary, log = True):\n",
    "    freq = np.array([0.]*128)\n",
    "    s_count = 0\n",
    "    for d in df['text']:\n",
    "        x, s = embed_sent(d, model, dictionary, sent_length = True)\n",
    "        freq += np.ceil(x - min(x))\n",
    "        s_count += s\n",
    "    # add small value to avoid division by 0\n",
    "    freq += 1e-07\n",
    "    freq = s_count/freq\n",
    "    if log:\n",
    "        freq = np.log(freq)\n",
    "        \n",
    "    # this happend when all sentences contain one common topic\n",
    "    # prones to happen when user writes few reviews\n",
    "    freq[np.where(freq < 0.0)] = 0.0\n",
    "    # pad topic that never used by this user\n",
    "    freq[np.where(np.log(s_count/1e-07) == freq)] = 0.0\n",
    "    return np.array(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business1 = reviews[reviews['business_id'] == 'v95ot_TNwTk1iJ5n56dR0g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_tf_business_idf(text, df, model, dictionary):\n",
    "    tf = augmented_embed_sent(text, model, dictionary)\n",
    "    idf = business_idf(df,model,dictionary)\n",
    "    out = np.multiply(tf, idf)\n",
    "    return out/sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01021194,  0.01278958,  0.01100246,  0.        ,  0.00858564,\n",
       "        0.01278958,  0.00953696,  0.        ,  0.01185225,  0.        ,\n",
       "        0.01278958,  0.01116327,  0.00863401,  0.00858564,  0.01278958,\n",
       "        0.00901341,  0.01021194,  0.01011446,  0.01116327,  0.01278958,\n",
       "        0.01367903,  0.01088368,  0.00892194,  0.01021194,  0.        ,\n",
       "        0.        ,  0.        ,  0.01682207,  0.01116327,  0.00953696,\n",
       "        0.        ,  0.01021194,  0.01278958,  0.        ,  0.00858564,\n",
       "        0.01278958,  0.00901341,  0.        ,  0.01116327,  0.00953696,\n",
       "        0.01325511,  0.01116327,  0.01116327,  0.01278958,  0.01021194,\n",
       "        0.01278958,  0.01290797,  0.0073871 ,  0.        ,  0.        ,\n",
       "        0.01116327,  0.        ,  0.00901341,  0.00822396,  0.00901341,\n",
       "        0.        ,  0.01116327,  0.01278958,  0.01278958,  0.01116327,\n",
       "        0.        ,  0.00953696,  0.01021194,  0.        ,  0.        ,\n",
       "        0.        ,  0.01278958,  0.01372438,  0.01019627,  0.01116327,\n",
       "        0.01021194,  0.01278958,  0.        ,  0.01536094,  0.        ,\n",
       "        0.01464172,  0.01278958,  0.00953696,  0.        ,  0.00791066,\n",
       "        0.01021194,  0.        ,  0.        ,  0.        ,  0.01278958,\n",
       "        0.        ,  0.        ,  0.00953696,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01116327,  0.        ,  0.        ,\n",
       "        0.01278958,  0.01278958,  0.01116327,  0.01278958,  0.        ,\n",
       "        0.01278958,  0.00901341,  0.01278958,  0.        ,  0.01278958,\n",
       "        0.01116327,  0.01116327,  0.        ,  0.01116327,  0.00953696,\n",
       "        0.01278958,  0.        ,  0.015673  ,  0.        ,  0.01465489,\n",
       "        0.01088615,  0.01278958,  0.00901341,  0.00822396,  0.01278958,\n",
       "        0.        ,  0.00822396,  0.        ,  0.01116327,  0.01116327,\n",
       "        0.00901341,  0.        ,  0.01278958])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tf_business_idf(user1['text'].values[0], business1, model, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Personal tf-idf * Business idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_tfidf_business_idf(text, udf, bdf, model, dictionary):\n",
    "    tf = augmented_embed_sent(text, model, dictionary)\n",
    "    uidf = user_idf(udf,model,dictionary)\n",
    "    idf = business_idf(bdf,model,dictionary)\n",
    "    out = np.multiply(np.multiply(tf, uidf), idf)\n",
    "    return out/sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01073831,  0.        ,  0.00777841,  0.01284868,  0.00666943,\n",
       "        0.01206795,  0.00874771,  0.01335381,  0.00781532,  0.        ,\n",
       "        0.01410924,  0.01277353,  0.00759198,  0.00691124,  0.00986501,\n",
       "        0.00700173,  0.01375743,  0.0103883 ,  0.01138609,  0.        ,\n",
       "        0.00953139,  0.00780205,  0.00804533,  0.00997581,  0.01118133,\n",
       "        0.        ,  0.        ,  0.01296637,  0.01326227,  0.00662182,\n",
       "        0.        ,  0.01019913,  0.0136503 ,  0.        ,  0.00674966,\n",
       "        0.01585406,  0.00809205,  0.01081587,  0.00975952,  0.01032098,\n",
       "        0.00964127,  0.01191454,  0.01142427,  0.        ,  0.01063329,\n",
       "        0.01180273,  0.00956448,  0.00545583,  0.01173868,  0.01354754,\n",
       "        0.00791371,  0.01074874,  0.00531086,  0.00512413,  0.00905983,\n",
       "        0.        ,  0.01014087,  0.01096348,  0.01277353,  0.01326227,\n",
       "        0.        ,  0.00824259,  0.00880105,  0.        ,  0.        ,\n",
       "        0.        ,  0.01185358,  0.01239577,  0.00794183,  0.00866337,\n",
       "        0.00836728,  0.01300606,  0.        ,  0.0141469 ,  0.        ,\n",
       "        0.00901777,  0.        ,  0.0066856 ,  0.        ,  0.00750602,\n",
       "        0.01021574,  0.        ,  0.        ,  0.00899163,  0.        ,\n",
       "        0.        ,  0.        ,  0.00869172,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01142427,  0.        ,  0.        ,\n",
       "        0.01344881,  0.01317393,  0.01081587,  0.01292614,  0.        ,\n",
       "        0.01195848,  0.00822392,  0.01386933,  0.        ,  0.01121486,\n",
       "        0.01025913,  0.0136503 ,  0.        ,  0.01277353,  0.00913604,\n",
       "        0.01675189,  0.        ,  0.01131448,  0.01675189,  0.00965807,\n",
       "        0.00971997,  0.01126124,  0.00876392,  0.00780599,  0.        ,\n",
       "        0.01423836,  0.00619582,  0.01110387,  0.0130886 ,  0.01191454,\n",
       "        0.00968092,  0.01114926,  0.01354754])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tfidf_business_idf(user1['text'].values[0], user1, business1, model, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train idf for the future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "uidf_data = {}\n",
    "zero_user = set()\n",
    "for u, df in reviews.groupby('user_id'):\n",
    "    uidf_data[u] = user_idf(df, model, dictionary)\n",
    "    if np.sum(np.ceil(uidf_data[u])) == 0.0:\n",
    "        zero_user.add(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bidf_data = {}\n",
    "zero_business = set()\n",
    "for u, df in reviews.groupby('business_id'):\n",
    "    bidf_data[u] = business_idf(df, model, dictionary)\n",
    "    if np.sum(np.ceil(bidf_data[u])) == 0.0:\n",
    "        zero_business.add(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('u_idf.pickle', 'wb') as f:\n",
    "    pickle.dump(uidf_data, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('zero_user.pickle', 'wb') as f:\n",
    "    pickle.dump(zero_user, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('b_idf.pickle', 'wb') as f:\n",
    "    pickle.dump(bidf_data, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
