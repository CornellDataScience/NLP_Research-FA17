{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalizing text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "import pickle\n",
    "import gensim\n",
    "from itertools import chain\n",
    "from gensim_lda_model import Gensimembedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load file\n",
    "business = pd.read_csv('chinese_business_clean.csv')\n",
    "reviews = pd.read_csv('chinese_reviews_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda =  models.LdaModel.load('gensim/lda.model')\n",
    "dictionary = corpora.Dictionary.load('gensim/chinsese_dict.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Gensimembedder(model = lda, dictionary = dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]\n",
    "\n",
    "def embed(text, model, dictionary):\n",
    "    text = tokenize(text)\n",
    "    bow = dictionary.doc2bow(text)\n",
    "    kindex = model.get_document_topics(bow, minimum_probability = 0.0)\n",
    "    out = [0] * model.num_topics\n",
    "    for i, p in kindex:\n",
    "        out[i] = p\n",
    "    return np.array(out) \n",
    "\n",
    "def embed_sent(text, model, dictionary):\n",
    "    out = np.array([0.]*128)\n",
    "    sentences = len(nltk.sent_tokenize(text))\n",
    "    for text in nltk.sent_tokenize(text):\n",
    "        out += embed(text, lda, dictionary)\n",
    "    return (out/sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24136</th>\n",
       "      <td>CxDOIDnH8gp9KXzpBHJYXw</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27171</th>\n",
       "      <td>EiP1OFgs-XGcKZux0OKWIA</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>2e5V6M4GNufEnbGJpVdCjw</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user_id  business_id  cool  date  funny  review_id  \\\n",
       "24136  CxDOIDnH8gp9KXzpBHJYXw          528   528   528    528        528   \n",
       "27171  EiP1OFgs-XGcKZux0OKWIA          189   189   189    189        189   \n",
       "6341   2e5V6M4GNufEnbGJpVdCjw          142   142   142    142        142   \n",
       "\n",
       "       stars  text  useful  \n",
       "24136    528   528     528  \n",
       "27171    189   189     189  \n",
       "6341     142   142     142  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top users\n",
    "reviews.groupby('user_id').count().reset_index().sort_values(by = 'review_id', ascending = False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1 = reviews[reviews['user_id'] == 'CxDOIDnH8gp9KXzpBHJYXw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vince Seafood Restaurant & BBQ has one of the most value in weekday dim sum offering around on a weekday morning! Before 11 am, it is 10% off $2.28  S/M/L size and free tea.\\n\\nNot surprisingly that it was packed with seniors that ordering a lot food to take out for lunch and dinner later to enjoy.\\n\\nDim Sum menu is quite interesting with a mix of classical and chiu chow style dim sum. And at this price point, my Yelp friend ordered quite a few and more from the menu.\\n \\nShrimp Dumpling \"Har Gow\" - A-OK\\nPork Dumpling with Liver on Top \"Siu Mai\" - Meh, not crazy about overcooked liver\\nPork Rib with Black Bean and Olive Sauce - good portion \\nBean Curd Skin Roll with Mix Chinese Vegetable - lacking filling\\nDumpling in Lotus Leaf - love this! great contrast of taste and texture! \\nBeef Tender in Spicy Sauce - Tender enough but really lacking any spice, more on the sweet side\\nCrystal Dumplings in Fish Papaya Soup - huge dumplings!!! shrimp has great bite!\\nRoast Pork Belly Roll - Not fatty enough and a little dry\\nRice Roll with Whole Shrimp - shrimp quite mushy and rice roll itself a little too thin\\n\\nOverall the quality and quantity are great! A little mix up here and there but service is friendly and decent.\\n\\nMy Yelp friend wants to try the Steamed Fish Intestine Egg Custard... I guess have to come back another time for that!'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1['text'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. get_document_topics function in gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.13109937,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.24101523,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.6206516 ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed(user1['text'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. sentence tokenize before embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V_{t} = \\frac{1}{s}\\sum_{s \\in \\text{sentences}} embed(s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.05784255,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.05784255,  0.        ,\n",
       "        0.        ,  0.        ,  0.00660969,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.00909441,  0.08505146,  0.01112667,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.0492811 ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.06708648,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.08927966,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.04504784,  0.00682388,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.06601992,  0.        ,\n",
       "        0.07020084,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.0699847 ,  0.        ,  0.16641546,\n",
       "        0.00868269,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed_sent(user1['text'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Augemented Frequency to normalize sentence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V_{t}(doc) = \\alpha + \\alpha * \\frac{embed_{t}}{max(embed_{t}:t \\in d)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augmented_embed_sent(text, model, dictionary, alpha = 0.5):\n",
    "    out = np.array([0.]*128)\n",
    "    sentences = len(nltk.sent_tokenize(text))\n",
    "    for text in nltk.sent_tokenize(text):\n",
    "        out += embed(text, lda, dictionary)\n",
    "    \n",
    "    out = alpha + alpha * out/max(out)\n",
    "    \n",
    "    return out/sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00744331,  0.00744331,  0.0105958 ,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.0105958 ,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00779619,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00793982,  0.01208403,  0.00804577,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.01012955,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.01007682,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.01409856,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00990621,  0.0078049 ,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.01104615,  0.00744331,\n",
       "        0.01227845,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.01126451,  0.00744331,  0.0147712 ,\n",
       "        0.0079155 ,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331,  0.00744331,  0.00744331,\n",
       "        0.00744331,  0.00744331,  0.00744331])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_embed_sent(user1['text'].values[0], model, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Personal tf-idf - most characteristic topic for particular user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$idf(t,D) = log\\frac{N}{|{d \\in D : t \\in d}|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_idf(df, model, dictionary):\n",
    "    user = df['user_id']\n",
    "    freq = np.array([0.]*128)\n",
    "    for d in df['text']:\n",
    "        x = embed_sent(d, model, dictionary)\n",
    "        freq += np.ceil(x - min(x))\n",
    "    freq = len(df)/freq\n",
    "    freq[np.where(np.isnan(freq))] = 0.0\n",
    "    freq = np.log(freq)\n",
    "    freq[np.where(np.isinf(freq))] = 0.0\n",
    "    return np.array(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.01099975,  3.37872453,  1.02207221,  2.74273576,  1.58696506,\n",
       "        2.28011224,  2.07944154,  2.8678989 ,  1.05961013,  2.80336038,\n",
       "        3.22457385,  2.80336038,  1.96503119,  1.76928661,  2.17475172,\n",
       "        1.6343673 ,  2.97325942,  2.44045489,  2.20865327,  2.39789527,\n",
       "        1.16922986,  1.3564414 ,  2.33727065,  2.24374459,  2.04958858,\n",
       "        3.78418963,  2.31785257,  1.87464713,  3.01099975,  1.67397643,\n",
       "        4.88280192,  2.55552422,  3.01099975,  4.32318613,  1.87464713,\n",
       "        4.07187171,  1.70474809,  2.02060104,  2.1419619 ,  2.74273576,\n",
       "        1.39389896,  3.22457385,  2.77258872,  4.47733681,  2.58021683,\n",
       "        2.35707328,  1.18149995,  1.27188401,  2.97325942,  2.97325942,\n",
       "        1.56861592,  1.91238746,  0.51652364,  1.37125648,  1.81474899,\n",
       "        3.49650756,  2.74273576,  2.55552422,  2.71374822,  3.09104245,\n",
       "        2.90180045,  1.7258015 ,  1.7258015 ,  3.3246573 ,  2.71374822,\n",
       "        1.78045991,  2.2617631 ,  2.31785257,  1.64412347,  2.04958858,\n",
       "        2.19155884,  2.97325942,  2.63151012,  2.39789527,  3.27336401,\n",
       "        1.01160091,  2.74273576,  1.65397577,  3.17805383,  2.06440366,\n",
       "        2.2617631 ,  3.43588294,  4.32318613,  2.24374459,  2.33727065,\n",
       "        2.83510908,  4.18965474,  2.31785257,  3.22457385,  2.83510908,\n",
       "        4.65965837,  3.13360207,  2.74273576,  3.37872453,  2.50789617,\n",
       "        3.13360207,  2.80336038,  1.92529086,  2.90180045,  3.78418963,\n",
       "        2.46243379,  1.96503119,  3.17805383,  2.65817837,  2.74273576,\n",
       "        2.63151012,  3.22457385,  2.58021683,  2.83510908,  1.86237704,\n",
       "        4.47733681,  3.63003895,  2.35707328,  4.88280192,  0.85745023,\n",
       "        2.31785257,  2.1102132 ,  2.2617631 ,  1.45691193,  3.05022046,\n",
       "        3.27336401,  1.83827948,  2.17475172,  2.93689177,  3.70414693,\n",
       "        2.48490665,  2.77258872,  3.05022046])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_idf(user1, model, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_tfidf_embed(text, df, model, dictionary, alpha = 0.5):\n",
    "    tf = augmented_embed_sent(text, model, dictionary)\n",
    "    idf = user_idf(df,model,dictionary)\n",
    "    out = np.multiply(tf, idf)\n",
    "    return out/sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00914555,  0.00954063,  0.00439538,  0.00868946,  0.00453543,\n",
       "        0.00691535,  0.00597841,  0.00879706,  0.00441809,  0.00794589,\n",
       "        0.00999672,  0.00858564,  0.0064462 ,  0.00554657,  0.00629014,\n",
       "        0.00495284,  0.00868946,  0.00754475,  0.00669194,  0.00735216,\n",
       "        0.00412028,  0.00655292,  0.00735437,  0.00658626,  0.00624355,\n",
       "        0.01279113,  0.00697394,  0.00780466,  0.00868946,  0.00489366,\n",
       "        0.01444688,  0.00770907,  0.00902477,  0.01239605,  0.00554657,\n",
       "        0.01279113,  0.00516981,  0.00593644,  0.00633748,  0.00829438,\n",
       "        0.00612192,  0.00983675,  0.00829438,  0.01279113,  0.00778592,\n",
       "        0.00669194,  0.00638858,  0.00374323,  0.00968499,  0.00940299,\n",
       "        0.00486451,  0.00533514,  0.00151887,  0.004386  ,  0.00554657,\n",
       "        0.01053616,  0.00735216,  0.00742018,  0.00829438,  0.00927147,\n",
       "        0.00868946,  0.00530133,  0.00507487,  0.00983675,  0.00829438,\n",
       "        0.00533514,  0.00697394,  0.00960942,  0.00521903,  0.00589506,\n",
       "        0.0061525 ,  0.00858564,  0.00802924,  0.0106238 ,  0.00968499,\n",
       "        0.00435721,  0.00848533,  0.00477875,  0.00927147,  0.00610801,\n",
       "        0.00669194,  0.01072237,  0.01239605,  0.00674623,  0.00680154,\n",
       "        0.00786482,  0.01173582,  0.00680154,  0.00927147,  0.00868946,\n",
       "        0.01529805,  0.00879706,  0.00829438,  0.01034521,  0.00709472,\n",
       "        0.00940299,  0.00829438,  0.00551027,  0.00838831,  0.01239605,\n",
       "        0.00697394,  0.00597841,  0.00940299,  0.00770907,  0.00902477,\n",
       "        0.00763416,  0.00940299,  0.00735216,  0.00829438,  0.0052679 ,\n",
       "        0.01239605,  0.0107403 ,  0.01069366,  0.01239605,  0.00535784,\n",
       "        0.00711724,  0.00638559,  0.00703371,  0.00458779,  0.00829438,\n",
       "        0.01016584,  0.00533514,  0.00629014,  0.00838831,  0.00914555,\n",
       "        0.00722064,  0.00778592,  0.00838831])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tfidf_embed(user1['text'].values[0], user1, model, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Personal tf * Business idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "business1 = reviews[reviews['business_id'] == 'v95ot_TNwTk1iJ5n56dR0g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def business_idf(df, model, dictionary):\n",
    "    freq = np.array([0.]*128)\n",
    "    for d in df['text']:\n",
    "        x = embed_sent(d, model, dictionary)\n",
    "        freq += np.ceil(x - min(x))\n",
    "    freq = len(df)/freq\n",
    "    freq[np.where(np.isnan(freq))] = 0.0\n",
    "    freq = np.log(freq)\n",
    "    freq[np.where(np.isinf(freq))] = 0.0\n",
    "    return np.array(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_tf_business_idf(text, df, model, dictionary):\n",
    "    tf = augmented_embed_sent(text, model, dictionary)\n",
    "    idf = business_idf(df,model,dictionary)\n",
    "    out = np.multiply(tf, idf)\n",
    "    return out/sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kentatakatsu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00852935,  0.        ,  0.00655224,  0.01528912,  0.00949032,\n",
       "        0.01190924,  0.00852935,  0.01528912,  0.00840161,  0.        ,\n",
       "        0.        ,  0.01528912,  0.00781218,  0.00744127,  0.        ,\n",
       "        0.00744127,  0.01528912,  0.00906416,  0.01528912,  0.        ,\n",
       "        0.01634783,  0.00345941,  0.00629688,  0.01190924,  0.01528912,\n",
       "        0.        ,  0.        ,  0.0164636 ,  0.01190924,  0.00655224,\n",
       "        0.        ,  0.00993213,  0.01190924,  0.        ,  0.00580058,\n",
       "        0.01528912,  0.00744127,  0.        ,  0.01528912,  0.00655224,\n",
       "        0.01100044,  0.01190924,  0.01190924,  0.        ,  0.00993213,\n",
       "        0.        ,  0.00617543,  0.00457514,  0.        ,  0.        ,\n",
       "        0.01190924,  0.01528912,  0.00993213,  0.00655224,  0.00852935,\n",
       "        0.        ,  0.00744127,  0.00852935,  0.01528912,  0.        ,\n",
       "        0.        ,  0.00744127,  0.01190924,  0.        ,  0.        ,\n",
       "        0.        ,  0.01528912,  0.01152132,  0.00927256,  0.00993213,\n",
       "        0.00993213,  0.01528912,  0.        ,  0.01801231,  0.        ,\n",
       "        0.01840545,  0.01528912,  0.00993213,  0.        ,  0.00580058,\n",
       "        0.01528912,  0.        ,  0.        ,  0.00993213,  0.        ,\n",
       "        0.        ,  0.        ,  0.00852935,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01190924,  0.        ,  0.        ,\n",
       "        0.        ,  0.01528912,  0.01190924,  0.01528912,  0.        ,\n",
       "        0.01528912,  0.00744127,  0.01528912,  0.        ,  0.01528912,\n",
       "        0.01190924,  0.01190924,  0.        ,  0.01190924,  0.00993213,\n",
       "        0.01528912,  0.        ,  0.01528912,  0.        ,  0.01021439,\n",
       "        0.01060194,  0.02359913,  0.00852935,  0.00655224,  0.        ,\n",
       "        0.01528912,  0.00457514,  0.01528912,  0.01528912,  0.01528912,\n",
       "        0.00744127,  0.01528912,  0.01528912])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tf_business_idf(user1['text'].values[0], business1, model, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Personal tf-idf * Business idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_tf_business_idf(text, udf, bdf, model, dictionary):\n",
    "    tf = augmented_embed_sent(text, model, dictionary)\n",
    "    uidf = user_idf(udf,model,dictionary)\n",
    "    idf = business_idf(bdf,model,dictionary)\n",
    "    out = np.multiply(np.multiply(tf, uidf), idf)\n",
    "    return out/sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kentatakatsu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.01077619,  0.        ,  0.00436463,  0.01956185,  0.00463277,\n",
       "        0.01531342,  0.007272  ,  0.        ,  0.00352725,  0.        ,\n",
       "        0.0209494 ,  0.01373315,  0.0060182 ,  0.0050527 ,  0.01100551,\n",
       "        0.00542355,  0.0188524 ,  0.00857802,  0.0115387 ,  0.        ,\n",
       "        0.00866978,  0.00179267,  0.00609366,  0.00897252,  0.        ,\n",
       "        0.        ,  0.        ,  0.00864915,  0.02008187,  0.00522989,\n",
       "        0.        ,  0.01170158,  0.        ,  0.        ,  0.00498869,\n",
       "        0.02645412,  0.00549083,  0.01370962,  0.01100551,  0.00849183,\n",
       "        0.00487731,  0.02159962,  0.01781899,  0.02721933,  0.01078547,\n",
       "        0.        ,  0.00251529,  0.00191317,  0.        ,  0.        ,\n",
       "        0.0067766 ,  0.        ,  0.00187207,  0.00275493,  0.0088424 ,\n",
       "        0.        ,  0.00917483,  0.01331698,  0.01821286,  0.01956185,\n",
       "        0.        ,  0.00614108,  0.00728366,  0.        ,  0.        ,\n",
       "        0.        ,  0.01557863,  0.01052528,  0.00640685,  0.01015364,\n",
       "        0.00732341,  0.        ,  0.        ,  0.01699592,  0.        ,\n",
       "        0.00637877,  0.        ,  0.00578546,  0.        ,  0.00524015,\n",
       "        0.01144584,  0.        ,  0.        ,  0.01481342,  0.        ,\n",
       "        0.        ,  0.        ,  0.00698379,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.0146848 ,  0.        ,  0.        ,\n",
       "        0.01931666,  0.0188524 ,  0.        ,  0.01821286,  0.        ,\n",
       "        0.01518477,  0.00877618,  0.01656513,  0.        ,  0.        ,\n",
       "        0.0130574 ,  0.        ,  0.01660272,  0.01781899,  0.00878769,\n",
       "        0.02908834,  0.        ,  0.01714185,  0.        ,  0.0036324 ,\n",
       "        0.00973537,  0.01092186,  0.01003318,  0.00468485,  0.02035837,\n",
       "        0.02195088,  0.00337594,  0.01423811,  0.01821286,  0.01738757,\n",
       "        0.01145325,  0.01387984,  0.01981666])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tf_business_idf(user1['text'].values[0], user1, business1, model, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
