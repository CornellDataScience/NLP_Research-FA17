{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Categorizing Yelp Businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a baseline based on the article from Yelp Software Team, [Automatically Categorizing Yelp Businesses](https://engineeringblog.yelp.com/2015/09/automatically-categorizing-yelp-businesses.html)  \n",
    "Not using text information, guess the multi-label assignment of business. Here, all sample set contains 'Chinese' tag and try to see if the model can detect more subtle labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import * \n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from co_occurrence_net.category_map import CategoryMap\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "chinese_business = pd.read_csv('chinese_business_clean.csv', index_col = False)\n",
    "chinese_reviews = pd.read_csv('chinese_review_clean.csv', index_col = False)\n",
    "chinese_business['categories'] =  [eval(i) for i in chinese_business['categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = CategoryMap()\n",
    "G.build_graph(chinese_business['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Asian Fusion', 449),\n",
       " ('Food', 398),\n",
       " ('Fast Food', 260),\n",
       " ('Thai', 237),\n",
       " ('Dim Sum', 230),\n",
       " ('Buffets', 211),\n",
       " ('Japanese', 179),\n",
       " ('Seafood', 163),\n",
       " ('Sushi Bars', 158),\n",
       " ('Specialty Food', 134)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.get_subcategories('Chinese')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Series of Binary Classifiers: One for Each Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is a business of a given category \n",
    "\n",
    "We extract terms from names and reviews, using standard lexical analysis techniques of tokenization, normalization (e.g. lowercasing), and stop word filtering. If the business has been categorized as part of a chain (which we’ll describe in an upcoming blog post!) we’ll include that chain’s URL as a feature, and if the business has NAICS codes from one of our data partners, we’ll include those as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_split(business_df, review_df, topic):\n",
    "    '''\n",
    "    Split the original data into 2 classes, ones that includes topic label and don't\n",
    "    '''\n",
    "    print ('topic: {}'.format(topic))\n",
    "    includes = set()\n",
    "    not_includes = set()\n",
    "    for i, topics in enumerate(business_df['categories']):\n",
    "        if topic in topics:\n",
    "            includes.add(business_df.iloc[i]['business_id'])\n",
    "        else:\n",
    "            not_includes.add(business_df.iloc[i]['business_id'])\n",
    "    review_included = review_df.loc[review_df['business_id'].isin(includes)]\n",
    "    review_not_included = review_df.loc[review_df['business_id'].isin(not_includes)]\n",
    "    print ('include topic:     {} business, {} reviews'.format(len(includes), len(review_included)))\n",
    "    print ('not include topic: {} business, {} reviews'.format(len(not_includes), len(review_not_included)))\n",
    "    \n",
    "    return review_included, review_not_included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: Dim Sum\n",
      "include topic:     230 business, 21960 reviews\n",
      "not include topic: 3545 business, 156189 reviews\n"
     ]
    }
   ],
   "source": [
    "t, f = data_split(chinese_business, chinese_reviews, G.get_subcategories('Chinese')[4][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yelp used following features:\n",
    "- Tokenized Name\n",
    "- Tokenized Review\n",
    "- NAICS(we do not have an access)\n",
    "- country (we disregard)\n",
    "- Last Term in Name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genereate_feature(review_counter, name_counter, review_df, business_df, business_id):\n",
    "    '''\n",
    "    '''    \n",
    "    # filter the restaurant name\n",
    "    name = business_df.loc[business_df['business_id'] == business_id]['name']\n",
    "\n",
    "    # filter the reviews for the specified business\n",
    "    review = review_df.loc[review_df['business_id'] == business_id]['text']\n",
    "    if (len(name_counter.build_analyzer()(name.values[0])) != 0):\n",
    "        # extract the last word of the restaurant\n",
    "        last_name = pd.Series(name_counter.build_analyzer()(name.values[0])[-1])\n",
    "\n",
    "        # feature length \n",
    "        name_length = len(name_counter.get_feature_names()) \n",
    "        review_length = len(review_counter.get_feature_names())\n",
    "\n",
    "        # NAME + LAST NAME + REVIEW\n",
    "        name_feature = np.zeros(name_length)\n",
    "        last_name_feature = np.zeros(name_length)\n",
    "        review_feature = np.zeros(review_length)\n",
    "\n",
    "        for r, d in zip(name_counter.transform(name).indices, name_counter.transform(name).data):\n",
    "            name_feature[r] = d\n",
    "\n",
    "        for r, d in zip(name_counter.transform(last_name).indices, name_counter.transform(last_name).data):\n",
    "            last_name_feature[r] = d\n",
    "\n",
    "        for r, d in zip(review_counter.transform(review).indices, review_counter.transform(review).data):\n",
    "            review_feature[r] = d\n",
    "\n",
    "        feature = np.array(np.concatenate((name_feature, last_name_feature, review_feature),axis = 0))\n",
    "        return feature\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data_set(review_counter, name_counter, review_df, business_df, topic):\n",
    "    '''\n",
    "    '''\n",
    "    # select business with topic tag\n",
    "    t, f = data_split(business_df, review_df, topic)\n",
    "    t_in =  (set(t['business_id']))\n",
    "    t_not_in =  (set(f['business_id']))\n",
    "    \n",
    "    # output dimension\n",
    "    name_length = len(name_counter.get_feature_names()) \n",
    "    review_length = len(review_counter.get_feature_names())\n",
    "    feature_length = 2*name_length + review_length\n",
    "    \n",
    "    X_in = np.array([])\n",
    "    Y_in = np.array([])\n",
    "    \n",
    "    for b in t_in:\n",
    "        feature = genereate_feature(review_counter, name_counter, review_df, business_df, b)\n",
    "        if feature:\n",
    "            X_in = np.append(X_in, feature)\n",
    "            Y_in = np.append(Y_in, 1)\n",
    "    print ('positive set done')\n",
    "    \n",
    "    X_out = np.array([])\n",
    "    Y_out = np.array([])\n",
    "    \n",
    "#     for b in t_not_in:\n",
    "#         feature = genereate_feature(review_counter, name_counter, review_df, business_df, b)\n",
    "#         X_out = np.append(X_out, feature)\n",
    "#         Y_out = np.append(Y_out, 0)\n",
    "#     print ('negative set done')\n",
    "    \n",
    "    \n",
    "    return X_in.reshape(len(t_in), feature_length), Y_in.reshape(-1,1), t_not_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build CountVectorizer for review and name\n",
    "review_counter = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "name_counter = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "\n",
    "# fit the CountVectorizer\n",
    "reviews = review_counter.fit_transform(chinese_reviews['text'])\n",
    "names = name_counter.fit_transform(chinese_business['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genereate_feature(review_counter, name_counter, chinese_reviews, chinese_business, 'OygJyqypKFZJIZ6r9dML7w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: Dim Sum\n",
      "include topic:     230 business, 21960 reviews\n",
      "not include topic: 3545 business, 156189 reviews\n",
      "positive set done\n"
     ]
    }
   ],
   "source": [
    "X, Y, not_list = create_data_set(review_counter, name_counter, chinese_reviews, chinese_business,'Dim Sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, some business is breaking my code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "investigation begins\n",
      "dAtT3iwh3Os5lkA7TySvNg\n",
      "investigation done\n"
     ]
    }
   ],
   "source": [
    "print ('investigation begins')\n",
    "\n",
    "bugs = []\n",
    "for b in not_list:\n",
    "    try:\n",
    "        feature = genereate_feature(review_counter, name_counter, chinese_reviews, chinese_business, b)\n",
    "#         X_in = np.append(X_in, feature)\n",
    "#         Y_in = np.append(Y_in, 1)\n",
    "    except:\n",
    "        print (b)\n",
    "        bugs.append(b)\n",
    "        \n",
    "print ('investigation done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>165 E Beaver Creek Road</td>\n",
       "      <td>{'RestaurantsTableService': True, 'GoodForMeal...</td>\n",
       "      <td>dAtT3iwh3Os5lkA7TySvNg</td>\n",
       "      <td>[Seafood, Chinese, Restaurants, Barbeque]</td>\n",
       "      <td>Richmond Hill</td>\n",
       "      <td>{'Monday': '11:00-23:00', 'Tuesday': '11:00-23...</td>\n",
       "      <td>1</td>\n",
       "      <td>43.847147</td>\n",
       "      <td>-79.378954</td>\n",
       "      <td>Top 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L4B 3P4</td>\n",
       "      <td>19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    address  \\\n",
       "64  165 E Beaver Creek Road   \n",
       "\n",
       "                                           attributes             business_id  \\\n",
       "64  {'RestaurantsTableService': True, 'GoodForMeal...  dAtT3iwh3Os5lkA7TySvNg   \n",
       "\n",
       "                                   categories           city  \\\n",
       "64  [Seafood, Chinese, Restaurants, Barbeque]  Richmond Hill   \n",
       "\n",
       "                                                hours  is_open   latitude  \\\n",
       "64  {'Monday': '11:00-23:00', 'Tuesday': '11:00-23...        1  43.847147   \n",
       "\n",
       "    longitude   name neighborhood postal_code  review_count  stars state  \n",
       "64 -79.378954  Top 1          NaN     L4B 3P4            19    3.0    ON  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_business.loc[chinese_business['business_id'] != 'dAtT3iwh3Os5lkA7TySvNg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both 'Top' and '1' appear only once in the dataset. This is actually a special snowflake. But this business has to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_business = chinese_business.loc[chinese_business['business_id'] != 'dAtT3iwh3Os5lkA7TySvNg']\n",
    "chinese_business.to_csv('chinese_business_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap from not list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "boots = random.sample((not_list), int(len(not_list)*0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative set done\n"
     ]
    }
   ],
   "source": [
    "# output dimension\n",
    "name_length = len(name_counter.get_feature_names()) \n",
    "review_length = len(review_counter.get_feature_names())\n",
    "feature_length = 2*name_length + review_length\n",
    "\n",
    "X_out = np.array([])\n",
    "Y_out = np.array([])\n",
    "for b in boots:\n",
    "    feature = genereate_feature(review_counter, name_counter, chinese_reviews, chinese_business, b)\n",
    "    X_out = np.append(X_out, feature)\n",
    "    Y_out = np.append(Y_out, 0)\n",
    "X_out = X_out.reshape(len(boots), feature_length)\n",
    "Y_out = Y_out.reshape(-1,1)\n",
    "print ('negative set done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original article builds Logistic Regression for each categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_train_o, X_test_o, y_train_o, y_test_o = train_test_split(X_out, Y_out, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, X_train_o))\n",
    "X_test = np.concatenate((X_test, X_test_o))\n",
    "\n",
    "Y_train = np.concatenate((y_train, y_train_o))\n",
    "Y_test = np.concatenate((y_test, y_test_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[136,   6],\n",
       "       [ 14,  32]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test.ravel(), lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76190476190476197"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test.ravel(), lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16672, 18463, 43749, ..., 13605, 38795, 12544]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.28791993010302286, 0.72338751229731657)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_[0,16672], lr.coef_[0,12544]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_feature(coef, name_counter, review_counter, n):\n",
    "    '''\n",
    "    coef has a sequence of NAME, LAST NAME, REVIEW VOCAB \n",
    "    extract the top n features from coef\n",
    "    '''\n",
    "    name_v = name_counter.get_feature_names()\n",
    "    review_v = review_counter.get_feature_names()\n",
    "    \n",
    "    name = coef[0][:len(name_v)]\n",
    "    last_name = coef[0][len(name_v):2*len(name_v)]\n",
    "    review = coef[0][2*len(name_v):]\n",
    "    \n",
    "    print ('name coefficient negative')\n",
    "    for u in np.argsort(name)[:n]:\n",
    "        print(name_v[u], name[u])\n",
    "    print ('\\n')\n",
    "    print ('name coefficient positive')\n",
    "    for u in np.argsort(name)[::-1][:n]:\n",
    "        print(name_v[u], name[u])\n",
    "    print ('\\n')\n",
    "    print ('last name coefficient negative')\n",
    "    for u in np.argsort(last_name)[:n]:\n",
    "        print(name_v[u], last_name[u])\n",
    "    print ('\\n')\n",
    "    print ('last name coefficient positive')\n",
    "    for u in np.argsort(last_name)[::-1][:n]:\n",
    "        print(name_v[u], last_name[u])\n",
    "    print ('\\n')\n",
    "    print ('review coefficient negative')\n",
    "    for u in np.argsort(review)[:n]:\n",
    "        print(review_v[u], review[u])\n",
    "    print ('\\n')\n",
    "    print ('review coefficient positive')\n",
    "    for u in np.argsort(review)[::-1][:n]:\n",
    "        print(review_v[u], review[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name coefficient negative\n",
      "china -0.157094805763\n",
      "buffet -0.101678068884\n",
      "garden -0.0734928673052\n",
      "chinese -0.072400178135\n",
      "food -0.051678281704\n",
      "\n",
      "\n",
      "name coefficient positive\n",
      "cuisine 0.0870469949447\n",
      "shanghai 0.0861585781651\n",
      "sum 0.0824983997347\n",
      "dim 0.0824983997347\n",
      "dumpling 0.0792403479249\n",
      "\n",
      "\n",
      "last name coefficient negative\n",
      "buffet -0.069676202635\n",
      "garden -0.0557880695568\n",
      "restaurant -0.0489154609091\n",
      "food -0.0487191831454\n",
      "dumplings -0.037461312508\n",
      "\n",
      "\n",
      "last name coefficient positive\n",
      "sum 0.0909825487412\n",
      "cuisine 0.0798585846448\n",
      "bistro 0.0657587489797\n",
      "360 0.0649416671561\n",
      "ring 0.0422551026267\n",
      "\n",
      "\n",
      "review coefficient negative\n",
      "food -0.287919930103\n",
      "good -0.277915695372\n",
      "went -0.264869671523\n",
      "pork -0.264361788662\n",
      "like -0.261832407678\n",
      "\n",
      "\n",
      "review coefficient positive\n",
      "dim 0.723387512297\n",
      "sum 0.63375841905\n",
      "dumpling 0.315769062247\n",
      "dimsum 0.302306118397\n",
      "dumplings 0.290983158503\n"
     ]
    }
   ],
   "source": [
    "get_best_feature(lr.coef_, name_counter, review_counter, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
